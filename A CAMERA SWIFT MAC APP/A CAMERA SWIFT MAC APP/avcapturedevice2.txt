        A continuity camera device. These devices are suitable for general purpose use. Note that devices of this type may only be discovered using an AVCaptureDeviceDiscoverySession or -[AVCaptureDevice defaultDeviceWithDeviceType:mediaType:position:].
     
     @discussion
        Starting in macOS 14.0 and Mac Catalyst 17.0, apps may opt in for using AVCaptureDeviceTypeContinuityCamera by adding the following key to their Info.plist:
            <key>NSCameraUseContinuityCameraDeviceType</key>
            <true/>
    
    	Otherwise, continuity cameras on macOS and Mac Catalyst report that their device type is AVCaptureDeviceTypeBuiltInWideAngleCamera.
     */
    @available(macOS 14.0, *)
    public static let continuityCamera: AVCaptureDevice.DeviceType

    /**
     @constant AVCaptureDeviceTypeDeskViewCamera
        A distortion corrected cut out from an ultra wide camera, made to approximate an overhead camera pointing at a desk. Supports multicam operation.
     */
    @available(macOS 13.0, *)
    public static let deskViewCamera: AVCaptureDevice.DeviceType

    /**
     @constant AVCaptureDeviceTypeExternalUnknown
        A deprecated synonym for AVCaptureDeviceTypeExternal. Please use AVCaptureDeviceTypeExternal instead.
     */
    @available(macOS, introduced: 10.15, deprecated: 14.0, renamed: "AVCaptureDevice.DeviceType.external")
    public static let externalUnknown: AVCaptureDevice.DeviceType

    /**
     @constant AVCaptureDeviceTypeBuiltInMicrophone
        A deprecated synonym for AVCaptureDeviceTypeMicrophone. Please use AVCaptureDeviceTypeMicrophone instead.
     */
    @available(macOS, introduced: 10.15, deprecated: 14.0, renamed: "AVCaptureDevice.DeviceType.microphone")
    public static let builtInMicrophone: AVCaptureDevice.DeviceType
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property deviceType
     @abstract
        The type of the capture device.
     
     @discussion
        A capture device's type never changes.
     */
    @available(macOS 10.15, *)
    open var deviceType: AVCaptureDevice.DeviceType { get }
}
@available(macOS 10.15, *)
extension AVCaptureDevice {

    /**
     @method defaultDeviceWithDeviceType:mediaType:position:
     @abstract
        Returns an AVCaptureDevice instance for the default device of the given device type, media type, and position.
     
     @param deviceType
        The device type supported by the returned device. It must be a valid AVCaptureDeviceType.
     @param mediaType
        The media type, such as AVMediaTypeVideo, AVMediaTypeAudio, or AVMediaTypeMuxed, supported by the returned device. Pass nil to consider devices with any media type.
     @param position
        The position supported by the returned device. Pass AVCaptureDevicePositionUnspecified to consider devices with any position.
     @result
        The default device with the given device type, media type and position or nil if no device with that media type exists and nil otherwise.
     
     @discussion
        This method returns the default device of the given combination of device type, media type, and position currently available on the system.
     */
    @available(macOS 10.15, *)
    open class func `default`(_ deviceType: AVCaptureDevice.DeviceType, for mediaType: AVMediaType?, position: AVCaptureDevice.Position) -> AVCaptureDevice?
}
@available(macOS 13.0, *)
extension AVCaptureDevice {

    /**
     @property userPreferredCamera
     @abstract
        Settable property that specifies a user preferred camera.
     
     @discussion
        Setting this property allows an application to persist its user’s preferred camera across app launches and reboots. The property internally maintains a short history, so if your user’s most recent preferred camera is not currently connected, it still reports the next best choice. This property always returns a device that is present. If no camera is available nil is returned. Setting the property to nil has no effect.
    */
    @available(macOS 13.0, *)
    open class var userPreferredCamera: AVCaptureDevice?

    /**
     @property systemPreferredCamera
     @abstract
        Specifies the best camera to use as determined by the system.
     
     @discussion
        Apple chooses the default value. This property incorporates userPreferredCamera as well as other factors, such as camera suspension and Apple cameras appearing that should be automatically chosen. The property may change spontaneously, such as when the preferred camera goes away. This property always returns a device that is present. If no camera is available nil is returned.
    
        Applications that adopt this API should always key-value observe this property and update their AVCaptureSession’s input device to reflect changes to the systemPreferredCamera. The application can still offer users the ability to pick a camera by setting userPreferredCamera, which will cause the systemPreferredCamera API to put the user’s choice first until either another Apple-preferred device becomes available or the machine is rebooted (after which it reverts to its original behavior of returning the internally determined best camera to use).
    
        If the application wishes to offer users a fully manual camera selection mode in addition to automatic camera selection, it is recommended to call setUserPreferredCamera: each time the user makes a camera selection, but ignore key-value observer updates to systemPreferredCamera while in manual selection mode.
    */
    @available(macOS 13.0, *)
    open class var systemPreferredCamera: AVCaptureDevice? { get }
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @method setPrimaryConstituentDeviceSwitchingBehavior:restrictedSwitchingBehaviorConditions:
     @abstract
        The switching behavior and conditions, unless overwritten via -[AVCaptureMovieFileOutput setPrimaryConstituentDeviceSwitchingBehavior:restrictedSwitchingBehaviorConditions].
     @param switchingBehavior
        The desired switching behavior.
     @param restrictedSwitchingBehaviorConditions
        The desired conditions for restricting camera switching. This must be set to AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionNone whenever switchingBehavior is not equal to AVCapturePrimaryConstituentDeviceSwitchingBehaviorRestricted.
     
     @discussion
        The switching behavior may be overridden on the AVCaptureMovieFileOutput while recording (see -[AVCaptureMovieFileOutput setPrimaryConstituentDeviceSwitchingBehavior:restrictedSwitchingBehaviorConditions]). This method throws an NSInvalidArgumentException if constituent device switching is not supported by the receiver or if restrictedSwitchingBehaviorConditions is not equal to AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionNone and switchingBehavior is not equal to AVCapturePrimaryConstituentDeviceSwitchingBehaviorRestricted.
     */
    @available(macOS 12.0, *)
    open func setPrimaryConstituentDeviceSwitchingBehavior(_ switchingBehavior: AVCaptureDevice.PrimaryConstituentDeviceSwitchingBehavior, restrictedSwitchingBehaviorConditions: AVCaptureDevice.PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions)

    /**
     @property primaryConstituentDeviceSwitchingBehavior
     @abstract
        The primaryConstituentDeviceSwitchingBehavior as set by -[AVCaptureDevice setPrimaryConstituentDeviceSwitchingBehavior:restrictedSwitchingBehaviorConditions:].
     
     @discussion
        By default, this property is set to AVCapturePrimaryConstituentDeviceSwitchingBehaviorAuto for AVCaptureDevices that support it.  This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var primaryConstituentDeviceSwitchingBehavior: AVCaptureDevice.PrimaryConstituentDeviceSwitchingBehavior { get }

    /**
     @property primaryConstituentDeviceRestrictedSwitchingBehaviorConditions
     @abstract
        The primaryConstituentDeviceRestrictedSwitchingBehaviorConditions as set by -[AVCaptureDevice setPrimaryConstituentDeviceSwitchingBehavior:restrictedSwitchingBehaviorConditions:].
     
     @discussion
        By default, this propety is set to AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionNone. This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var primaryConstituentDeviceRestrictedSwitchingBehaviorConditions: AVCaptureDevice.PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions { get }

    /**
     @property activePrimaryConstituentDeviceSwitchingBehavior
     @abstract
        The active constituent device switching behavior.
     
     @discussion
        For virtual devices with multiple constituent devices, this property returns the active switching behavior. This is equal to primaryConstituentDeviceSwitchingBehavior except while recording using an AVCaptureMovieFileOutput configured with a different switching behavior (see -[AVCaptureMovieFileOutput setPrimaryConstituentDeviceSwitchingBehavior:restrictedSwitchingBehaviorConditions]). Devices that do not support constituent device switching return AVCapturePrimaryConstituentDeviceSwitchingBehaviorUnsupported. This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var activePrimaryConstituentDeviceSwitchingBehavior: AVCaptureDevice.PrimaryConstituentDeviceSwitchingBehavior { get }

    /**
     @property activePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions
     @abstract
        The active constituent device restricted  switching behavior.
     
     @discussion
        For virtual devices with multiple constituent devices, this property returns the active restricted switching behavior conditions. This is equal to primaryConstituentDeviceRestrictedSwitchingBehaviorConditions except while recording using an AVCaptureMovieFileOutput configured with different retricted switching behavior conditions (see -[AVCaptureMovieFileOutput setPrimaryConstituentDeviceSwitchingBehaviorForRecording:restrictedSwitchingBehaviorConditions]). Devices that do not support constituent device switching return AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionNone. This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var activePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions: AVCaptureDevice.PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions { get }

    /**
     @property activePrimaryConstituentDevice
     @abstract
        For virtual devices, this property indicates which constituent device is currently the primary constituent device. The primary constituent device may change when zoom, exposure, or focus changes.
     
     @discussion
        This property returns nil for non-virtual devices. On virtual devices this property returns nil until the device is used in a running AVCaptureSession. This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var activePrimaryConstituent: AVCaptureDevice? { get }

    /**
     @property supportedFallbackPrimaryConstituentDevices
     @abstract
        The constituent devices that may be selected as a fallback for a longer focal length primary constituent device.
     
     @discussion
        This property returns an empty array for non-virtual devices. This property never changes for a given virtual device.
     */
    @available(macOS 12.0, *)
    open var supportedFallbackPrimaryConstituentDevices: [AVCaptureDevice] { get }

    /**
     @property fallbackPrimaryConstituentDevices
     @abstract
        The constituent devices that may be used as a fallback device when a constituent device with a longer focal length becomes limited by its light sensitivity or minimum focus distance.
     
     @discussion
        This may only be set to the supportedFallbackPrimaryConstituentDevices or a subset thereof. By default this is set to all supportedFallbackPrimaryConstituentDevices. This property will throw an NSInvalidArgumentException if the array includes any device not reported in supportedFallbackPrimaryConstituentDevices. This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var fallbackPrimaryConstituentDevices: [AVCaptureDevice]
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property hasFlash
     @abstract
        Indicates whether the receiver has a flash.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver has a flash. The receiver's flashMode property can only be set when this property returns YES.
     */
    open var hasFlash: Bool { get }

    /**
     @property flashAvailable
     @abstract
        Indicates whether the receiver's flash is currently available for use.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver's flash is currently available. The flash may become unavailable if, for example, the device overheats and needs to cool off. This property is key-value observable.
     */
    @available(macOS 10.15, *)
    open var isFlashAvailable: Bool { get }

    /**
     @method isFlashModeSupported:
     @abstract
        Returns whether the receiver supports the given flash mode.
     
     @param flashMode
        An AVCaptureFlashMode to be checked.
     @result
        YES if the receiver supports the given flash mode, NO otherwise.
     
     @discussion
        The receiver's flashMode property can only be set to a certain mode if this method returns YES for that mode.
     */
    open func isFlashModeSupported(_ flashMode: AVCaptureDevice.FlashMode) -> Bool

    /**
     @property flashMode
     @abstract
        Indicates current mode of the receiver's flash, if it has one.
     
     @discussion
        The value of this property is an AVCaptureFlashMode that determines the mode of the receiver's flash, if it has one. -setFlashMode: throws an NSInvalidArgumentException if set to an unsupported value (see -isFlashModeSupported:). -setFlashMode: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's flashMode by key value observing this property.
     
        When using AVCapturePhotoOutput, AVCaptureDevice's flashMode property is ignored. You specify flashMode on a per photo basis by setting the AVCapturePhotoSettings.flashMode property.
     */
    open var flashMode: AVCaptureDevice.FlashMode
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property hasTorch
     @abstract
        Indicates whether the receiver has a torch.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver has a torch. The receiver's torchMode property can only be set when this property returns YES.
     */
    open var hasTorch: Bool { get }

    /**
     @property torchAvailable
     @abstract
        Indicates whether the receiver's torch is currently available for use.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver's torch is currently available. The torch may become unavailable if, for example, the device overheats and needs to cool off. This property is key-value observable.
     */
    @available(macOS 10.15, *)
    open var isTorchAvailable: Bool { get }

    /**
     @property torchActive
     @abstract
        Indicates whether the receiver's torch is currently active.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver's torch is currently active. If the current torchMode is AVCaptureTorchModeAuto and isTorchActive is YES, the torch will illuminate once a recording starts (see AVCaptureOutput.h -startRecordingToOutputFileURL:recordingDelegate:). This property is key-value observable.
     */
    @available(macOS 10.15, *)
    open var isTorchActive: Bool { get }

    /**
     @property torchLevel
     @abstract
        Indicates the receiver's current torch brightness level as a floating point value.
     
     @discussion
        The value of this property is a float indicating the receiver's torch level from 0.0 (off) -> 1.0 (full). This property is key-value observable.
     */
    @available(macOS 10.15, *)
    open var torchLevel: Float { get }

    /**
     @method isTorchModeSupported:
     @abstract
        Returns whether the receiver supports the given torch mode.
     
     @param torchMode
        An AVCaptureTorchMode to be checked.
     @result
        YES if the receiver supports the given torch mode, NO otherwise.
     
     @discussion
        The receiver's torchMode property can only be set to a certain mode if this method returns YES for that mode.
     */
    open func isTorchModeSupported(_ torchMode: AVCaptureDevice.TorchMode) -> Bool

    /**
     @property torchMode
     @abstract
        Indicates current mode of the receiver's torch, if it has one.
     
     @discussion
        The value of this property is an AVCaptureTorchMode that determines the mode of the receiver's torch, if it has one. -setTorchMode: throws an NSInvalidArgumentException if set to an unsupported value (see -isTorchModeSupported:). -setTorchMode: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's torchMode by key value observing this property.
     */
    open var torchMode: AVCaptureDevice.TorchMode

    /**
     @method setTorchModeOnWithLevel:error:
     @abstract
        Sets the current mode of the receiver's torch to AVCaptureTorchModeOn at the specified level.
     
     @discussion
        This method sets the torch mode to AVCaptureTorchModeOn at a specified level. torchLevel must be a value between 0 and 1, or the special value AVCaptureMaxAvailableTorchLevel. The specified value may not be available if the iOS device is too hot. This method throws an NSInvalidArgumentException if set to an unsupported level. If the specified level is valid, but unavailable, the method returns NO with AVErrorTorchLevelUnavailable. -setTorchModeOnWithLevel:error: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's torchMode by key value observing the torchMode property.
     */
    @available(macOS 10.15, *)
    open func setTorchModeOn(level torchLevel: Float) throws
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @method isFocusModeSupported:
     @abstract
        Returns whether the receiver supports the given focus mode.
     
     @param focusMode
        An AVCaptureFocusMode to be checked.
     @result
        YES if the receiver supports the given focus mode, NO otherwise.
     
     @discussion
        The receiver's focusMode property can only be set to a certain mode if this method returns YES for that mode.
     */
    open func isFocusModeSupported(_ focusMode: AVCaptureDevice.FocusMode) -> Bool

    /**
     @property focusMode
     @abstract
        Indicates current focus mode of the receiver, if it has one.
     
     @discussion
        The value of this property is an AVCaptureFocusMode that determines the receiver's focus mode, if it has one. -setFocusMode: throws an NSInvalidArgumentException if set to an unsupported value (see -isFocusModeSupported:). -setFocusMode: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's focusMode by key value observing this property.
     */
    open var focusMode: AVCaptureDevice.FocusMode

    /**
     @property focusPointOfInterestSupported
     @abstract
        Indicates whether the receiver supports focus points of interest.
     
     @discussion
        The receiver's focusPointOfInterest property can only be set if this property returns YES.
     */
    open var isFocusPointOfInterestSupported: Bool { get }

    /**
     @property focusPointOfInterest
     @abstract
        Indicates current focus point of interest of the receiver, if it has one.
     
     @discussion
        The value of this property is a CGPoint that determines the receiver's focus point of interest, if it has one. A value of (0,0) indicates that the camera should focus on the top left corner of the image, while a value of (1,1) indicates that it should focus on the bottom right. The default value is (0.5,0.5). -setFocusPointOfInterest: throws an NSInvalidArgumentException if isFocusPointOfInterestSupported returns NO. -setFocusPointOfInterest: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's focusPointOfInterest by key value observing this property. Note that setting focusPointOfInterest alone does not initiate a focus operation. After setting focusPointOfInterest, call -setFocusMode: to apply the new point of interest.
     */
    open var focusPointOfInterest: CGPoint

    /**
     @property adjustingFocus
     @abstract
        Indicates whether the receiver is currently performing a focus scan to adjust focus.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver's camera focus is being automatically adjusted by means of a focus scan, because its focus mode is AVCaptureFocusModeAutoFocus or AVCaptureFocusModeContinuousAutoFocus. Clients can observe the value of this property to determine whether the camera's focus is stable.
     @seealso lensPosition
     @seealso AVCaptureAutoFocusSystem
     */
    open var isAdjustingFocus: Bool { get }

    /**
     @property minimumFocusDistance
     @abstract
        A property indicating the minimum focus distance.
     
     @discussion
        The minimum focus distance is given in millimeters, -1 if unknown. For virtual cameras (AVCaptureDeviceTypeBuiltInDualCamera, AVCaptureDeviceTypeBuiltInTripleCamera, etc.), the value reported is the smallest minimum focus distance of the auto-focus-capable cameras that it sources.
     */
    @available(macOS 12.0, *)
    open var minimumFocusDistance: Int { get }
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @method isExposureModeSupported:
     @abstract
        Returns whether the receiver supports the given exposure mode.
     
     @param exposureMode
        An AVCaptureExposureMode to be checked.
     @result
        YES if the receiver supports the given exposure mode, NO otherwise.
     
     @discussion
        The receiver's exposureMode property can only be set to a certain mode if this method returns YES for that mode.
     */
    open func isExposureModeSupported(_ exposureMode: AVCaptureDevice.ExposureMode) -> Bool

    /**
     @property exposureMode
     @abstract
        Indicates current exposure mode of the receiver, if it has adjustable exposure.
     
     @discussion
        The value of this property is an AVCaptureExposureMode that determines the receiver's exposure mode, if it has adjustable exposure. -setExposureMode: throws an NSInvalidArgumentException if set to an unsupported value (see -isExposureModeSupported:). -setExposureMode: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. When using AVCapturePhotoOutput and capturing photos with AVCapturePhotoSettings' photoQualityPrioritization property set to AVCapturePhotoQualityPrioritizationBalanced or higher, the receiver's ISO and exposureDuration values may be overridden when exposing the photo if the scene is dark enough to warrant some form of multi-image fusion to improve quality. To ensure that the receiver's ISO and exposureDuration values are honored while in AVCaptureExposureModeCustom or AVCaptureExposureModeLocked, you must set your AVCapturePhotoSettings.photoQualityPrioritization property to AVCapturePhotoQualityPrioritizationSpeed. The same rule applies if you are using the deprecated AVCapturePhotoSettings.autoStillImageStabilizationEnabled property; you must set it to NO to preserve your custom exposure values in the photo capture. Likewise if you're using AVCaptureStillImageOutput, automaticallyEnablesStillImageStabilizationWhenAvailable must be set to NO to preserve your custom exposure values in a still image capture. Clients can observe automatic changes to the receiver's exposureMode by key value observing this property.
     */
    open var exposureMode: AVCaptureDevice.ExposureMode

    /**
     @property exposurePointOfInterestSupported:
     @abstract
        Indicates whether the receiver supports exposure points of interest.
     
     @discussion
        The receiver's exposurePointOfInterest property can only be set if this property returns YES.
     */
    open var isExposurePointOfInterestSupported: Bool { get }

    /**
     @property exposurePointOfInterest
     @abstract
        Indicates current exposure point of interest of the receiver, if it has one.
     
     @discussion
        The value of this property is a CGPoint that determines the receiver's exposure point of interest, if it has adjustable exposure. A value of (0,0) indicates that the camera should adjust exposure based on the top left corner of the image, while a value of (1,1) indicates that it should adjust exposure based on the bottom right corner. The default value is (0.5,0.5). -setExposurePointOfInterest: throws an NSInvalidArgumentException if isExposurePointOfInterestSupported returns NO. -setExposurePointOfInterest: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Note that setting exposurePointOfInterest alone does not initiate an exposure operation. After setting exposurePointOfInterest, call -setExposureMode: to apply the new point of interest.
     */
    open var exposurePointOfInterest: CGPoint

    /**
     @property adjustingExposure
     @abstract
        Indicates whether the receiver is currently adjusting camera exposure.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver's camera exposure is being automatically adjusted because its exposure mode is AVCaptureExposureModeAutoExpose or AVCaptureExposureModeContinuousAutoExposure. Clients can observe the value of this property to determine whether the camera exposure is stable or is being automatically adjusted.
     */
    open var isAdjustingExposure: Bool { get }
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @method isWhiteBalanceModeSupported:
     @abstract
        Returns whether the receiver supports the given white balance mode.
     
     @param whiteBalanceMode
        An AVCaptureWhiteBalanceMode to be checked.
     @result
        YES if the receiver supports the given white balance mode, NO otherwise.
     
     @discussion
        The receiver's whiteBalanceMode property can only be set to a certain mode if this method returns YES for that mode.
     */
    open func isWhiteBalanceModeSupported(_ whiteBalanceMode: AVCaptureDevice.WhiteBalanceMode) -> Bool

    /**
     @property whiteBalanceMode
     @abstract
        Indicates current white balance mode of the receiver, if it has adjustable white balance.
     
     @discussion
        The value of this property is an AVCaptureWhiteBalanceMode that determines the receiver's white balance mode, if it has adjustable white balance. -setWhiteBalanceMode: throws an NSInvalidArgumentException if set to an unsupported value (see -isWhiteBalanceModeSupported:). -setWhiteBalanceMode: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's whiteBalanceMode by key value observing this property.
     */
    open var whiteBalanceMode: AVCaptureDevice.WhiteBalanceMode

    /**
     @property adjustingWhiteBalance
     @abstract
        Indicates whether the receiver is currently adjusting camera white balance.
     
     @discussion
        The value of this property is a BOOL indicating whether the receiver's camera white balance is being automatically adjusted because its white balance mode is AVCaptureWhiteBalanceModeAutoWhiteBalance or AVCaptureWhiteBalanceModeContinuousAutoWhiteBalance. Clients can observe the value of this property to determine whether the camera white balance is stable or is being automatically adjusted.
     */
    open var isAdjustingWhiteBalance: Bool { get }
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property displayVideoZoomFactorMultiplier
     @abstract
        A multiplier that can be used with the receiver's videoZoomFactor property for displaying a video zoom factor in a user interface.
     
     @discussion
        In some system user interfaces, like the macOS Video Effects Menu, the video zoom factor value is displayed in a way most appropriate for visual representation and might differ from the videoZoomFactor property value on the receiver by a fixed ratio. For example, if the videoZoomFactor property value is 1.0 and the displayVideoZoomFactorMultiplier property value is 0.5, then multiplying 1.0 and 0.5 produces 0.5 which can be displayed in the UI. Client applications can key value observe this property to update the display video zoom factor values in their UI to stay consistent with Apple's system UIs.
      */
    @available(macOS 14.0, *)
    open var displayVideoZoomFactorMultiplier: CGFloat { get }
}
/**
 @enum AVAuthorizationStatus
 @abstract
    Constants indicating the client's authorization to the underlying hardware supporting a media type.
 
 @constant AVAuthorizationStatusNotDetermined
    Indicates that the user has not yet made a choice regarding whether the client can access the hardware.
 @constant AVAuthorizationStatusRestricted
    The client is not authorized to access the hardware for the media type. The user cannot change the client's status, possibly due to active restrictions such as parental controls being in place.
 @constant AVAuthorizationStatusDenied
    The user explicitly denied access to the hardware supporting a media type for the client.
 @constant AVAuthorizationStatusAuthorized
    The client is authorized to access the hardware supporting a media type.
 */
@available(macOS 10.14, *)
public enum AVAuthorizationStatus : Int, @unchecked Sendable {

    case notDetermined = 0

    case restricted = 1

    case denied = 2

    case authorized = 3
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @method authorizationStatusForMediaType:
     @abstract
        Returns the client's authorization status for accessing the underlying hardware that supports a given media type.
     
     @param mediaType
        The media type, either AVMediaTypeVideo or AVMediaTypeAudio
     @result
        The authorization status of the client
     
     @discussion
        This method returns the AVAuthorizationStatus of the client for accessing the underlying hardware supporting the media type. Media type constants are defined in AVMediaFormat.h. If any media type other than AVMediaTypeVideo or AVMediaTypeAudio is supplied, an NSInvalidArgumentException will be thrown. If the status is AVAuthorizationStatusNotDetermined, you may use the +requestAccessForMediaType:completionHandler: method to request access by prompting the user.
     */
    @available(macOS 10.14, *)
    open class func authorizationStatus(for mediaType: AVMediaType) -> AVAuthorizationStatus

    /**
     @method requestAccessForMediaType:completionHandler:
     @abstract
        Requests access to the underlying hardware for the media type, showing a dialog to the user if necessary.
     
     @param mediaType
        The media type, either AVMediaTypeVideo or AVMediaTypeAudio
     @param handler
        A block called with the result of requesting access
     
     @discussion
        Use this function to request access to the hardware for a given media type. Media type constants are defined in AVMediaFormat.h. If any media type other than AVMediaTypeVideo or AVMediaTypeAudio is supplied, an NSInvalidArgumentException will be thrown.
     
        This call will not block while the user is being asked for access, allowing the client to continue running. Until access has been granted, any AVCaptureDevices for the media type will vend silent audio samples or black video frames. The user is only asked for permission the first time the client requests access. Later calls use the permission granted by the user.
     
        Note that the authorization dialog will automatically be shown if the status is AVAuthorizationStatusNotDetermined when creating an AVCaptureDeviceInput.
     
        Invoking this method with AVMediaTypeAudio is equivalent to calling -[AVAudioSession requestRecordPermission:].
    
        The completion handler is called on an arbitrary dispatch queue. It is the client's responsibility to ensure that any UIKit-related updates are called on the main queue or main thread as a result.
     */
    @available(macOS 10.14, *)
    open class func requestAccess(for mediaType: AVMediaType, completionHandler handler: @escaping (Bool) -> Void)

    /**
     @method requestAccessForMediaType:completionHandler:
     @abstract
        Requests access to the underlying hardware for the media type, showing a dialog to the user if necessary.
     
     @param mediaType
        The media type, either AVMediaTypeVideo or AVMediaTypeAudio
     @param handler
        A block called with the result of requesting access
     
     @discussion
        Use this function to request access to the hardware for a given media type. Media type constants are defined in AVMediaFormat.h. If any media type other than AVMediaTypeVideo or AVMediaTypeAudio is supplied, an NSInvalidArgumentException will be thrown.
     
        This call will not block while the user is being asked for access, allowing the client to continue running. Until access has been granted, any AVCaptureDevices for the media type will vend silent audio samples or black video frames. The user is only asked for permission the first time the client requests access. Later calls use the permission granted by the user.
     
        Note that the authorization dialog will automatically be shown if the status is AVAuthorizationStatusNotDetermined when creating an AVCaptureDeviceInput.
     
        Invoking this method with AVMediaTypeAudio is equivalent to calling -[AVAudioSession requestRecordPermission:].
    
        The completion handler is called on an arbitrary dispatch queue. It is the client's responsibility to ensure that any UIKit-related updates are called on the main queue or main thread as a result.
     */
    @available(macOS 10.14, *)
    open class func requestAccess(for mediaType: AVMediaType) async -> Bool
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property transportControlsSupported
     @abstract
        Returns whether the receiver supports transport control commands.
     
     @discussion
        For devices with transport controls, such as AVC tape-based camcorders or pro capture devices with RS422 deck control, the value of this property is YES. If transport controls are not supported, none of the associated transport control methods and properties are available on the receiver.
     */
    open var transportControlsSupported: Bool { get }

    /**
     @property transportControlsPlaybackMode
     @abstract
        Returns the receiver's current playback mode.
     
     @discussion
        For devices that support transport control, this property may be queried to discover the current playback mode.
     */
    open var transportControlsPlaybackMode: AVCaptureDevice.TransportControlsPlaybackMode { get }

    /**
     @property transportControlsSpeed
     @abstract
        Returns the receiver's current playback speed as a floating point value.
     
     @discussion
        For devices that support transport control, this property may be queried to discover the current playback speed of the deck.
        0.0 -> stopped.
        1.0 -> forward at normal speed.
        -1.0-> reverse at normal speed.
        2.0 -> forward at 2x normal speed.
        etc.
     */
    open var transportControlsSpeed: AVCaptureDevice.TransportControlsSpeed { get }

    /**
     @method setTransportControlsPlaybackMode:speed:
     @abstract
        Sets both the transport controls playback mode and speed in a single method.
     
     @param mode
        A AVCaptureDeviceTransportControlsPlaybackMode indicating whether the deck should be put into play mode.
     @param speed
        A AVCaptureDeviceTransportControlsSpeed indicating the speed at which to wind or play the tape.
     
     @discussion
        A method for setting the receiver's transport controls playback mode and speed. The receiver must be locked for configuration using lockForConfiguration: before clients can set this method, otherwise an NSGenericException is thrown.
     */
    open func setTransportControlsPlaybackMode(_ mode: AVCaptureDevice.TransportControlsPlaybackMode, speed: AVCaptureDevice.TransportControlsSpeed)
}
/**
 @enum AVCaptureColorSpace
 @abstract
    Constants indicating active or supported video color space.
 
 @constant AVCaptureColorSpace_sRGB
    The sRGB color space ( https://www.w3.org/Graphics/Color/srgb )
 @constant AVCaptureColorSpace_P3_D65
    The P3 D65 wide color space which uses Illuminant D65 as the white point.
 @constant AVCaptureColorSpace_HLG_BT2020
    The BT2020 wide color space which uses Illuminant D65 as the white point and Hybrid Log-Gamma as the transfer function.
 @constant AVCaptureColorSpace_AppleLog
    The Apple Log Color space, which uses BT2020 as the color primaries, and an Apple defined Log curve as a transfer function. When this is set as the active color space on an AVCaptureDevice, any AVCapturePhotoOutput or AVCaptureStillImageOutput connected to the same AVCaptureDevice will have its video connection disabled.
 */
@available(macOS 10.15, *)
public enum AVCaptureColorSpace : Int, @unchecked Sendable {

    case sRGB = 0

    case P3_D65 = 1
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property activeColorSpace
     @abstract
        Indicates the receiver's current active color space.
     
     @discussion
        By default, an AVCaptureDevice attached to an AVCaptureSession is automatically configured for wide color by the AVCaptureSession (see AVCaptureSession automaticallyConfiguresCaptureDeviceForWideColor). You may also set the activeColorSpace manually. To prevent the AVCaptureSession from undoing your work, remember to set AVCaptureSession's automaticallyConfiguresCaptureDeviceForWideColor property to NO. Changing the receiver's activeColorSpace while the session is running requires a disruptive reconfiguration of the capture render pipeline. Movie captures in progress will be ended immediately; unfulfilled photo requests will be aborted; video preview will temporarily freeze. -setActiveColorSpace: throws an NSGenericException if called without first obtaining exclusive access to the receiver using -lockForConfiguration:.
     */
    @available(macOS 10.15, *)
    open var activeColorSpace: AVCaptureColorSpace
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property centerStageControlMode
     @abstract
        A class property indicating the current mode of Center Stage control (user, app, or cooperative).
     
     @discussion
        This class property determines how the Center Stage feature is controlled. When set to the default value of AVCaptureCenterStageControlModeUser, centerStageEnabled may not be set programmatically and throws an NSInvalidArgumentException. In User mode, the feature may only be set by the user in Control Center. If you wish to take Center Stage control away from the user and exclusively enable / disable it programmatically, set this property to AVCaptureCenterStageControlModeApp. When under exclusive app control, Center Stage user control is disallowed (for instance, the toggle is grayed out in Control Center). If you wish to take control of Center Stage, but also cooperate with the user by listening for and appropriately reacting to their changes to the centerStageEnabled property, set this property to AVCaptureCenterStageControlModeCooperative. Note that in this mode, the onus is on you, the app developer, to honor user intent and conform your AVCaptureSession configuration to make Center Stage active (see the AVCaptureDevice instance property centerStageActive). In cooperative mode, the centerStageEnabled property may change at any time (such as when the user enables / disables the feature in Control Center).
     */
    @available(macOS 12.3, *)
    open class var centerStageControlMode: AVCaptureDevice.CenterStageControlMode

    /**
     @property centerStageEnabled
     @abstract
        A class property indicating whether the Center Stage feature is currently enabled or disabled (such as in Control Center or programmatically via your app).
     
     @discussion
        This property may only be set if centerStageControlMode is AVCaptureCenterStageControlModeApp or AVCaptureCenterStageControlModeCooperative, and otherwise throws an NSInvalidArgumentException. When centerStageControlMode is AVCaptureCenterStageControlModeUser or AVCaptureCenterStageControlModeCooperative, this property may change according to user desire (such as enabling / disabling the feature in Control Center), so you should key-value observe it.
     */
    @available(macOS 12.3, *)
    open class var isCenterStageEnabled: Bool

    /**
     @property centerStageActive
     @abstract
        Indicates whether Center Stage is currently active on a particular AVCaptureDevice.
     
     @discussion
        This readonly property returns YES when Center Stage is currently active on the receiver. When active, the camera automatically adjusts to keep people optimally framed within the field of view. The field of view may pan, tighten or widen as needed. Certain restrictions come into play when Center Stage is active:
            - The device's minAvailableVideoZoomFactor and maxAvailableVideoZoomFactor become restricted (see AVCaptureDeviceFormat's videoMinZoomFactorForCenterStage and videoMaxZoomFactorForCenterStage).
            - The device's activeVideoMinFrameDuration and activeVideoMaxFrameDuration are limited (see AVCaptureDeviceFormat's videoFrameRateRangeForCenterStage).
        Center Stage may be enabled via user control or application control, depending on the current +AVCaptureDevice.centerStageControlMode. When +AVCaptureDevice.centerStageEnabled is YES, a particular AVCaptureDevice instance may return YES for this property, depending whether it supports the feature in its current configuration. Some device features are mutually exclusive to Center Stage:
            - If depth data delivery is enabled on any output, such as AVCaptureDepthDataOutput, or -AVCapturePhotoOutput.depthDataDeliveryEnabled, Center Stage is deactivated.
            - If geometricDistortionCorrectionSupported is YES, geometricDistortionCorrectionEnabled must also be YES, or Center Stage is deactivated.
        This property is key-value observable.
     */
    @available(macOS 12.3, *)
    open var isCenterStageActive: Bool { get }

    /**
     @property centerStageRectOfInterest
     @abstract
        Specifies the effective region within the output pixel buffer that will be used to perform Center Stage framing.
     
     @discussion
        Applications that wish to apply additional processing (such as cropping) on top of Center Stage's output can use this property to guide Center Stage's framing.
     
        The rectangle's origin is top left and is relative to the coordinate space of the output pixel buffer. The default value of this property is the value CGRectMake(0, 0, 1, 1), where {0,0} represents the top left of the picture area, and {1,1} represents the bottom right on an unrotated picture. This rectangle of interest is applied prior to rotation, mirroring or scaling.
     
        Pixels outside of this rectangle of interest will be blackened out.
     
        Setting this property has no impact on objects specified in the metadata output.
     
        -setCenterStageRectOfInterest: throws an NSGenericException if called without first obtaining exclusive access to the receiver using -lockForConfiguration:. -setCenterStageRectOfInterest: throws an NSInvalidArgumentException if none of the AVCaptureDeviceFormats supported by the receiver support CenterStage. -setCenterStageRectOfInterest: throws an NSInvalidArgumentException if +centerStageEnabled is NO on the AVCaptureDevice class. -setCenterStageRectOfInterest: throws an NSInvalidArgumentException if the provided rectOfInterest goes outside the normalized (0-1) coordinate space.
     */
    @available(macOS 13.3, *)
    open var centerStageRectOfInterest: CGRect
}
@available(macOS 12.0, *)
extension AVCaptureDevice {

    /**
     @property portraitEffectEnabled
     @abstract
        A class property indicating whether the Portrait Effect feature is currently enabled in Control Center.
     
     @discussion
        This property changes to reflect the Portrait Effect state in Control Center. It is key-value observable. On iOS, Portrait Effect only applies to video conferencing apps by default (apps that use "voip" as one of their UIBackgroundModes). Non video conferencing apps may opt in for the Portrait Effect by adding the following key to their Info.plist:
            <key>NSCameraPortraitEffectEnabled</key>
            <true/>
     */
    @available(macOS 12.0, *)
    open class var isPortraitEffectEnabled: Bool { get }

    /**
     @property portraitEffectActive
     @abstract
        Indicates whether Portrait Effect is currently active for a particular AVCaptureDevice.
     
     @discussion
        This readonly property returns YES when Portrait Effect is currently active on the receiver. When active, the device blurs the background, simulating a shallow depth of field effect. Certain restrictions come into play when Portrait Effect is active:
            - The device's activeVideoMinFrameDuration and activeVideoMaxFrameDuration are limited (see AVCaptureDeviceFormat's videoFrameRateRangeForPortraitEffect).
        Note that when +AVCaptureDevice.portraitEffectEnabled is YES, a particular AVCaptureDevice instance may return YES for this property, depending whether it supports the feature in its current configuration.
        This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open var isPortraitEffectActive: Bool { get }
}
@available(macOS 14.0, *)
extension AVCaptureDevice {

    /**
     @property reactionEffectsEnabled
     @abstract
        A class property indicating whether the application is suitable for reaction effects, either by automatic gesture detection, or by calls to -[AVCaptureDevice performEffectForReaction:]. Reactions are only rendered when the device's activeFormat.reactionEffectsSupported is also YES, which will be reflected by canPerformReactionEffects when the feature is both enabled and supported.
     
     @discussion
        On macOS, Reaction Effects are enabled by default for all applications. On iOS, Reaction Effects are enabled by default for video conferencing applications (apps that use "voip" as one of their UIBackgroundModes). Non video conferencing applications may opt in for Reaction Effects by adding the following key to their Info.plist:
            <key>NSCameraReactionEffectsEnabled</key>
            <true/>
     */
    @available(macOS 14.0, *)
    open class var reactionEffectsEnabled: Bool { get }

    /**
     @property reactionEffectGesturesEnabled
     @abstract
        A class property indicating whether gesture detection will trigger reaction effects on the video stream. Gesture detection will only run when the device's activeFormat.reactionEffectsSupported is also YES, which will be reflected by canPerformReactionEffects.
     
     @discussion
        This property changes to reflect the Gestures state in Control Center. It is key-value observable. Clients can call performEffectForReaction: independently of whether gesture detection is enabled, reaction effects from either source will be intermixed.
     */
    @available(macOS 14.0, *)
    open class var reactionEffectGesturesEnabled: Bool { get }

    /**
     @property canPerformReactionEffects
     @abstract
        Indicates whether reactions can be performed on a particular AVCaptureDevice. This requires reactionEffectsEnabled to be YES, as well as using a AVCaptureDeviceFormat with reactionEffectsSupported.
     
     @discussion
        This readonly property returns YES when resources for reactions are available on the device instance. When YES, calls to performEffectForReaction: will render on the video feed, otherwise those calls are ignored. It is key-value observable.
     */
    @available(macOS 14.0, *)
    open var canPerformReactionEffects: Bool { get }

    /**
     @property availableReactionTypes
     @abstract
        Returns a list of reaction types which can be passed to performEffectForReaction.
     
     @discussion
        The list may differ between devices, or be affected by changes to active format, and can be key-value observed.
     */
    @available(macOS 14.0, *)
    open var availableReactionTypes: Set<AVCaptureReactionType> { get }

    /**
     @method performEffectForReaction:
     @abstract
        Triggers a specified reaction on the video stream.
     
     @param reactionType
        Indicates which reaction to perform.
     
     @discussion
        The entries in reactionEffectsInProgress may not reflect one-to-one against calls to this method. Depending on reaction style or resource limits, triggering multiple overlapping reactions of the same type may be coalesced into extending an existing reaction rather than overlaying a new one.
        
        The reactionType requested must be one of those listed in availableReactionTypes or an exception will be thrown. Performing a reaction when canPerformReactionEffects is NO is ignored, and VoIP applications are encouraged to transmit and display such reactions outside of the video feed.
     */
    @available(macOS 14.0, *)
    open func performEffect(for reactionType: AVCaptureReactionType)

    /**
     @property reactionEffectsInProgress
     @abstract
        Contains an array of reaction effects that are currently being performed by the device, sorted by timestamp. If observing old and new values in the KVO callback, the reaction effects which are still running in the new array will have kCMTimeInvalid as their endTime property. Reaction effects which have ended will only be in the old array, and will have their endTime property set to the presentation time of the first frame where the reaction effect was no longer present.
     
     @discussion
        Reaction effects which are triggered by either a call to performEffectForReaction: or by the automatic gesture detection will be reflected in this array. It is key-value observable to be notified when reaction effects begin or end.
     */
    @available(macOS 14.0, *)
    open var reactionEffectsInProgress: [AVCaptureReactionEffectState] { get }
}
@available(macOS 13.0, *)
extension AVCaptureDevice {

    /**
     @property continuityCamera
     @abstract
        A property that reports YES if the receiver is a Continuity Camera.
     
     @discussion
        Access this property to discover if the receiver is a Continuity Camera (external iPhone webcam).
    */
    @available(macOS 13.0, *)
    open var isContinuityCamera: Bool { get }
}
@available(macOS 13.0, *)
extension AVCaptureDevice {

    /**
     @property companionDeskViewCamera
     @abstract
        A reference to the Desk View Camera that is associated with and derived from this camera.
     
     @discussion
        The companionDeskViewCamera property allows you to discover if the receiver has a paired Desk View Camera which derives its desk framing from the receiver's ultra wide frame. In the presence of multiple Continuity Cameras, this property allows you to pair a particular Continuity Camera with its associated Desk View Camera.
    */
    @available(macOS 13.0, *)
    open var companionDeskViewCamera: AVCaptureDevice? { get }
}
@available(macOS 12.0, *)
extension AVCaptureDevice {

    /**
     @property preferredMicrophoneMode
     @abstract
        Indicates the microphone mode that has been selected by the user in Control Center.
    
     @discussion
        This readonly property returns the microphone mode selected by the user in Control Center. It is key-value observable.
     */
    @available(macOS 12.0, *)
    open class var preferredMicrophoneMode: AVCaptureDevice.MicrophoneMode { get }

    /**
     @property activeMicrophoneMode
     @abstract
        Indicates the currently active microphone mode.
    
     @discussion
        This readonly property returns the currently active microphone mode, which may differ from the preferredMicrophoneMode if the application's active audio route does not support the preferred microphone mode. This property is key-value observable.
     */
    @available(macOS 12.0, *)
    open class var activeMicrophoneMode: AVCaptureDevice.MicrophoneMode { get }
}
@available(macOS 12.0, *)
extension AVCaptureDevice {

    /**
     @method showSystemUserInterface:
     @abstract
        Displays the system's user interface for video effects or microphone modes.
     
     @param systemUserInterface
        The system UI to show.
     
     @discussion
        This method allows the calling application to prompt the user to make changes to Video Effects (such as Center Stage or the Portrait Effect) or Microphone Modes. It brings up the system user interface and deep links to the appropriate module. This method is non-blocking. After presenting the desired system user interface, control returns immediately to the application.
     */
    @available(macOS 12.0, *)
    open class func showSystemUserInterface(_ systemUserInterface: AVCaptureDevice.SystemUserInterface)
}
/**
 @class AVFrameRateRange
 @abstract
    An AVFrameRateRange expresses a range of valid frame rates as min and max rate and min and max duration.
 
 @discussion
    An AVCaptureDevice exposes an array of formats, and its current activeFormat may be queried. The payload for the formats property is an array of AVCaptureDeviceFormat objects and the activeFormat property payload is an AVCaptureDeviceFormat. AVCaptureDeviceFormat wraps a CMFormatDescription and expresses a range of valid video frame rates as an NSArray of AVFrameRateRange objects. AVFrameRateRange expresses min and max frame rate as a rate in frames per second and duration (CMTime). An AVFrameRateRange object is immutable. Its values do not change for the life of the object.
 */
@available(macOS 10.7, *)
open class AVFrameRateRange : NSObject {

    /**
     @property minFrameRate
     @abstract
        A Float64 indicating the minimum frame rate supported by this range.
     
     @discussion
        This read-only property indicates the minimum frame rate supported by this range in frames per second.
     */
    open var minFrameRate: Float64 { get }

    /**
     @property maxFrameRate
     @abstract
        A Float64 indicating the maximum frame rate supported by this range.
     
     @discussion
        This read-only property indicates the maximum frame rate supported by this range in frames per second.
     */
    open var maxFrameRate: Float64 { get }

    /**
     @property maxFrameDuration
     @abstract
        A CMTime indicating the maximum frame duration supported by this range.
     
     @discussion
        This read-only property indicates the maximum frame duration supported by this range. It is the reciprocal of minFrameRate, and expresses minFrameRate as a duration.
     */
    open var maxFrameDuration: CMTime { get }

    /**
     @property minFrameDuration
     @abstract
        A CMTime indicating the minimum frame duration supported by this range.
     
     @discussion
        This read-only property indicates the minimum frame duration supported by this range. It is the reciprocal of maxFrameRate, and expresses maxFrameRate as a duration.
     */
    open var minFrameDuration: CMTime { get }
}
extension AVCaptureDevice.Format {

    /**
     @enum AVCaptureAutoFocusSystem
     @abstract
        Constants indicating the autofocus system.
     
     @constant AVCaptureAutoFocusSystemNone
        Indicates that autofocus is not available.
     @constant AVCaptureAutoFocusSystemContrastDetection
        Indicates that autofocus is achieved by contrast detection. Contrast detection performs a focus scan to find the optimal position.
     @constant AVCaptureAutoFocusSystemPhaseDetection
        Indicates that autofocus is achieved by phase detection. Phase detection has the ability to achieve focus in many cases without a focus scan. Phase detection autofocus is typically less visually intrusive than contrast detection autofocus.
     */
    @available(macOS 10.15, *)
    public enum AutoFocusSystem : Int, @unchecked Sendable {

        case none = 0

        case contrastDetection = 1

        case phaseDetection = 2
    }
}
@available(macOS 10.7, *)
extension AVCaptureDevice.Format {

    /**
     @property centerStageSupported
     @abstract
        Indicates whether the format supports the Center Stage feature.
     
     @discussion
        This property returns YES if the format supports "Center Stage", which automatically adjusts the camera to keep people optimally framed within the field of view. See +AVCaptureDevice.centerStageEnabled for a detailed discussion.
     */
    @available(macOS 12.3, *)
    open var isCenterStageSupported: Bool { get }

    @available(macOS 12.3, *)
    open var videoMinZoomFactorForCenterStage: CGFloat { get }

    /**
     @property videoMaxZoomFactorForCenterStage
     @abstract
        Indicates the maximum zoom factor available for the AVCaptureDevice's videoZoomFactor property when centerStageActive is YES.
     
     @discussion
        Devices support a limited zoom range when Center Stage is active. If this device format does not support Center Stage, this property returns videoMaxZoomFactor.
     */
    @available(macOS 12.3, *)
    open var videoMaxZoomFactorForCenterStage: CGFloat { get }

    /**
     @property videoFrameRateRangeForCenterStage
     @abstract
        Indicates the minimum / maximum frame rates available when centerStageActive is YES.
     
     @discussion
        Devices may support a limited frame rate range when Center Stage is active. If this device format does not support Center Stage, this property returns nil.
     */
    @available(macOS 12.3, *)
    open var videoFrameRateRangeForCenterStage: AVFrameRateRange? { get }
}
@available(macOS 12.0, *)
extension AVCaptureDevice.Format {

    /**
     @property portraitEffectSupported
     @abstract
        Indicates whether the format supports the Portrait Effect feature.
     
     @discussion
        This property returns YES if the format supports Portrait Effect, the application of a shallow depth of field effect to objects in the background. See +AVCaptureDevice.portraitEffectEnabled for a detailed discussion.
     */
    @available(macOS 12.0, *)
    open var isPortraitEffectSupported: Bool { get }

    /**
     @property videoFrameRateRangeForPortraitEffect
     @abstract
        Indicates the minimum / maximum frame rates available when portraitEffectActive is YES.
     
     @discussion
        Devices may support a limited frame rate range when Portrait Effect is active. If this device format does not support Portrait Effect, this property returns nil.
     */
    @available(macOS 12.0, *)
    open var videoFrameRateRangeForPortraitEffect: AVFrameRateRange? { get }
}
@available(macOS 13.0, *)
extension AVCaptureDevice {

    /**
     @property studioLightEnabled
     @abstract
        A class property indicating whether the Studio Light feature is currently enabled in Control Center.
     
     @discussion
        This property changes to reflect the Studio Light state in Control Center. It is key-value observable.  On iOS, Studio Light only applies to video conferencing apps by default (apps that use "voip" as one of their UIBackgroundModes). Non video conferencing apps may opt in for Studio Light by adding the following key to their Info.plist:
            <key>NSCameraStudioLightEnabled</key>
            <true/>
     */
    @available(macOS 13.0, *)
    open class var isStudioLightEnabled: Bool { get }

    /**
     @property studioLightActive
     @abstract
        Indicates whether Studio Light is currently active on a particular AVCaptureDevice.
     
     @discussion
        This readonly property returns YES when Studio Light is currently active on the receiver. When active, the subject's face is artificially lit to simulate the presence of a studio light near the camera.
     */
    @available(macOS 13.0, *)
    open var isStudioLightActive: Bool { get }
}
@available(macOS 13.0, *)
extension AVCaptureDevice.Format {

    /**
     @property studioLightSupported
     @abstract
        Indicates whether the format supports the Studio Light feature.
     
     @discussion
        This property returns YES if the format supports Studio Light (artificial re-lighting of the subject's face). See +AVCaptureDevice.studioLightEnabled.
     */
    @available(macOS 13.0, *)
    open var isStudioLightSupported: Bool { get }

    /**
     @property videoFrameRateRangeForStudioLight
     @abstract
        Indicates the minimum / maximum frame rates available when studioLight is YES.
     
     @discussion
        Devices may support a limited frame rate range when Studio Light is active. If this device format does not support Studio Light, this property returns nil.
     */
    @available(macOS 13.0, *)
    open var videoFrameRateRangeForStudioLight: AVFrameRateRange? { get }
}
@available(macOS 14.0, *)
extension AVCaptureDevice.Format {

    /**
     @property reactionEffectsSupported
     @abstract
        Indicates whether the format supports the Reaction Effects feature.
     
     @discussion
        This property returns YES if the format supports Reaction Effects. See +AVCaptureDevice.reactionEffectsEnabled.
     */
    @available(macOS 14.0, *)
    open var reactionEffectsSupported: Bool { get }

    /**
     @property videoFrameRateRangeForReactionEffectsInProgress
     @abstract
        Indicates the minimum / maximum frame rates available when a reaction effect is running.
     
     @discussion
        Unlike the other video effects, enabling reaction effects does not limit the stream's frame rate because most of the time no rendering is being performed. The frame rate will only ramp down when a reaction is actually being rendered on the stream (see AVCaptureDevice.reactionEffectsInProgress)
     */
    @available(macOS 14.0, *)
    open var videoFrameRateRangeForReactionEffectsInProgress: AVFrameRateRange? { get }
}

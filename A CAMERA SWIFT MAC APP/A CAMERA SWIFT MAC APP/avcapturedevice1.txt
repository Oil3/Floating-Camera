
extension NSNotification.Name {

    
    /**
     @constant AVCaptureDeviceWasConnectedNotification
     @abstract
        Posted when a device becomes available on the system.
     
     @discussion
        The notification object is an AVCaptureDevice instance representing the device that became available.
     */
    @available(macOS 10.7, *)
    public static let AVCaptureDeviceWasConnected: NSNotification.Name

    
    /**
     @constant AVCaptureDeviceWasDisconnectedNotification
     @abstract
        Posted when a device becomes unavailable on the system.
     
     @discussion
        The notification object is an AVCaptureDevice instance representing the device that became unavailable.
     */
    @available(macOS 10.7, *)
    public static let AVCaptureDeviceWasDisconnected: NSNotification.Name
}


/**
 @class AVCaptureDevice
 @abstract
    An AVCaptureDevice represents a physical device that provides realtime input media data, such as video and audio.
 
 @discussion
    Each instance of AVCaptureDevice corresponds to a device, such as a camera or microphone. Instances of AVCaptureDevice cannot be created directly. An array of all currently available devices can also be obtained using the AVCaptureDeviceDiscoverySession. Devices can provide one or more streams of a given media type. Applications can search for devices matching desired criteria by using AVCaptureDeviceDiscoverySession, or may obtain a reference to the default device matching desired criteria by using +[AVCaptureDevice defaultDeviceWithDeviceType:mediaType:position:].
 
    Instances of AVCaptureDevice can be used to provide media data to an AVCaptureSession by creating an AVCaptureDeviceInput with the device and adding that to the capture session.
 */
@available(macOS 10.7, *)
open class AVCaptureDevice : NSObject {

    
    /**
     @method devices
     @abstract
        Returns an array of devices currently available for use as media input sources.
     
     @result
        An NSArray of AVCaptureDevice instances for each available device.
     
     @discussion
        This method returns an array of AVCaptureDevice instances for input devices currently connected and available for capture. The returned array contains all devices that are available at the time the method is called. Applications should observe AVCaptureDeviceWasConnectedNotification and AVCaptureDeviceWasDisconnectedNotification to be notified when the list of available devices has changed.
     */
    @available(macOS, introduced: 10.7, deprecated: 10.15, message: "Use AVCaptureDeviceDiscoverySession instead.")
    open class func devices() -> [AVCaptureDevice]

    
    /**
     @method devicesWithMediaType:
     @abstract
        Returns an array of devices currently available for use as sources of media with the given media type.
     
     @param mediaType
        The media type, such as AVMediaTypeVideo, AVMediaTypeAudio, or AVMediaTypeMuxed, supported by each returned device.
     @result
        An NSArray of AVCaptureDevice instances for each available device.
     
     @discussion
        This method returns an array of AVCaptureDevice instances for input devices currently connected and available for capture that provide media of the given type. Media type constants are defined in AVMediaFormat.h. The returned array contains all devices that are available at the time the method is called. Applications should observe AVCaptureDeviceWasConnectedNotification and AVCaptureDeviceWasDisconnectedNotification to be notified when the list of available devices has changed.
     */
    @available(macOS, introduced: 10.7, deprecated: 10.15, message: "Use AVCaptureDeviceDiscoverySession instead.")
    open class func devices(for mediaType: AVMediaType) -> [AVCaptureDevice]

    
    /**
     @method defaultDeviceWithMediaType:
     @abstract
        Returns an AVCaptureDevice instance for the default device of the given media type.
     
     @param mediaType
        The media type, such as AVMediaTypeVideo, AVMediaTypeAudio, or AVMediaTypeMuxed, supported by the returned device.
     @result
        The default device with the given media type, or nil if no device with that media type exists.
     
     @discussion
        This method returns the default device of the given media type currently available on the system. For example, for AVMediaTypeVideo, this method will return the built in camera that is primarily used for capture and recording. Media type constants are defined in AVMediaFormat.h.
     */
    open class func `default`(for mediaType: AVMediaType) -> AVCaptureDevice?

    
    /**
     @method deviceWithUniqueID:
     @abstract
        Returns an AVCaptureDevice instance with the given unique ID.
     
     @param deviceUniqueID
        The unique ID of the device instance to be returned.
     @result
        An AVCaptureDevice instance with the given unique ID, or nil if no device with that unique ID is available.
     
     @discussion
        Every available capture device has a unique ID that persists on one system across device connections and disconnections, application restarts, and reboots of the system itself. This method can be used to recall or track the status of a specific device whose unique ID has previously been saved.
     */
    public /*not inherited*/ init?(uniqueID deviceUniqueID: String)

    
    /**
     @property uniqueID
     @abstract
        An ID unique to the model of device corresponding to the receiver.
     
     @discussion
        Every available capture device has a unique ID that persists on one system across device connections and disconnections, application restarts, and reboots of the system itself. Applications can store the value returned by this property to recall or track the status of a specific device in the future.
     */
    open var uniqueID: String { get }

    
    /**
     @property modelID
     @abstract
        The model ID of the receiver.
     
     @discussion
        The value of this property is an identifier unique to all devices of the same model. The value is persistent across device connections and disconnections, and across different systems. For example, the model ID of the camera built in to two identical iPhone models will be the same even though they are different physical devices.
     */
    open var modelID: String { get }

    
    /**
     @property localizedName
     @abstract
        A localized human-readable name for the receiver.
     
     @discussion
        This property can be used for displaying the name of a capture device in a user interface.
     */
    open var localizedName: String { get }

    
    /**
     @property manufacturer
     @abstract
        The human-readable manufacturer name for the receiver.
     
     @discussion
        This property can be used to identify capture devices from a particular manufacturer. All Apple devices return "Apple Inc.". Devices from third party manufacturers may return an empty string.
     */
    @available(macOS 10.9, *)
    open var manufacturer: String { get }

    
    /**
     @property transportType
     @abstract
        The transport type of the receiver (e.g. USB, PCI, etc).
     
     @discussion
        This property can be used to discover the transport type of a capture device. Transport types are defined in <IOKit/audio/IOAudioTypes.h> as kIOAudioDeviceTransportType*.
     */
    open var transportType: Int32 { get }

    
    /**
     @method hasMediaType:
     @abstract
        Returns whether the receiver provides media with the given media type.
     
     @param mediaType
        A media type, such as AVMediaTypeVideo, AVMediaTypeAudio, or AVMediaTypeMuxed.
     @result
        YES if the device outputs the given media type, NO otherwise.
     
     @discussion
        Media type constants are defined in AVMediaFormat.h.
     */
    open func hasMediaType(_ mediaType: AVMediaType) -> Bool

    
    /**
     @method lockForConfiguration:
     @abstract
        Requests exclusive access to configure device hardware properties.
     
     @param outError
        On return, if the device could not be locked, points to an NSError describing why the failure occurred.
     @result
        A BOOL indicating whether the device was successfully locked for configuration.
     
     @discussion
        In order to set hardware properties on an AVCaptureDevice, such as focusMode and exposureMode, clients must first acquire a lock on the device. Clients should only hold the device lock if they require settable device properties to remain unchanged. Holding the device lock unnecessarily may degrade capture quality in other applications sharing the device.
     */
    open func lockForConfiguration() throws

    
    /**
     @method unlockForConfiguration
     @abstract
        Release exclusive control over device hardware properties.
     
     @discussion
        This method should be called to match an invocation of lockForConfiguration: when an application no longer needs to keep device hardware properties from changing automatically.
     */
    open func unlockForConfiguration()

    
    /**
     @method supportsAVCaptureSessionPreset:
     @abstract
        Returns whether the receiver can be used in an AVCaptureSession configured with the given preset.
     
     @param preset
        An AVCaptureSession preset.
     @result
        YES if the receiver can be used with the given preset, NO otherwise.
     
     @discussion
        An AVCaptureSession instance can be associated with a preset that configures its inputs and outputs to fulfill common use cases. This method can be used to determine if the receiver can be used in a capture session with the given preset. Presets are defined in AVCaptureSession.h.
     */
    open func supportsSessionPreset(_ preset: AVCaptureSession.Preset) -> Bool

    
    /**
     @property connected
     @abstract
        Indicates whether the device is connected and available to the system.
     
     @discussion
        The value of this property is a BOOL indicating whether the device represented by the receiver is connected and available for use as a capture device. Clients can key value observe the value of this property to be notified when a device is no longer available. When the value of this property becomes NO for a given instance, it will not become YES again. If the same physical device again becomes available to the system, it will be represented using a new instance of AVCaptureDevice.
     */
    open var isConnected: Bool { get }

    
    /**
     @property inUseByAnotherApplication
     @abstract
        Indicates whether the device is in use by another application.
     
     @discussion
        The value of this property is a BOOL indicating whether the device represented by the receiver is in use by another application. Clients can key value observe the value of this property to be notified when another app starts or stops using this device.
     */
    open var isInUseByAnotherApplication: Bool { get }

    
    /**
     @property suspended
     @abstract
        Indicates whether the device is suspended.
     
     @discussion
        The value of this property is a BOOL indicating whether the device represented by the receiver is currently suspended. Some devices disallow data capture due to a feature on the device. For example, isSuspended returns YES for the external iSight when its privacy iris is closed, or for the internal iSight on a notebook when the notebook's display is closed. Clients can key value observe the value of this property to be notified when the device becomes suspended or unsuspended.
     */
    open var isSuspended: Bool { get }

    
    /**
     @property linkedDevices
     @abstract
        An array of AVCaptureDevice objects physically linked to the receiver.
     
     @discussion
        The value of this property is an array of AVCaptureDevice objects that are a part of the same physical device as the receiver. For example, for the external iSight camera, linkedDevices returns an array containing an AVCaptureDevice for the external iSight microphone.
     */
    open var linkedDevices: [AVCaptureDevice] { get }

    
    /**
     @property formats
     @abstract
        An array of AVCaptureDeviceFormat objects supported by the receiver.
     
     @discussion
        This property can be used to enumerate the formats natively supported by the receiver. The capture device's activeFormat property may be set to one of the formats in this array. Clients can observe automatic changes to the receiver's formats by key value observing this property.
     */
    open var formats: [AVCaptureDevice.Format] { get }

    
    /**
     @property activeFormat
     @abstract
        The currently active format of the receiver.
     
     @discussion
        This property can be used to get or set the currently active device format.
     
        -setActiveFormat: throws an NSInvalidArgumentException if set to a format not present in the formats array.
     
        -setActiveFormat: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:.
     
        Clients can observe automatic changes to the receiver's activeFormat by key value observing this property.
     
        On iOS, use of AVCaptureDevice's setActiveFormat: and AVCaptureSession's setSessionPreset: are mutually exclusive. If you set a capture device's active format, the session to which it is attached changes its preset to AVCaptureSessionPresetInputPriority. Likewise if you set the AVCaptureSession's sessionPreset property, the session assumes control of its input devices, and configures their activeFormat appropriately. Note that audio devices do not expose any user-configurable formats on iOS. To configure audio input on iOS, you should use the AVAudioSession APIs instead (see AVAudioSession.h).
     
        The activeFormat, activeVideoMinFrameDuration, and activeVideoMaxFrameDuration properties may be set simultaneously by using AVCaptureSession's begin/commitConfiguration methods:
     
        [session beginConfiguration]; // the session to which the receiver's AVCaptureDeviceInput is added.
        if ( [device lockForConfiguration:&error] ) {
            [device setActiveFormat:newFormat];
            [device setActiveVideoMinFrameDuration:newMinDuration];
            [device setActiveVideoMaxFrameDuration:newMaxDuration];
            [device unlockForConfiguration];
        }
        [session commitConfiguration]; // The new format and frame rates are applied together in commitConfiguration
     
        Note that when configuring a session to use an active format intended for high resolution still photography and applying one or more of the following operations to an AVCaptureVideoDataOutput, the system may not meet the target framerate: zoom, orientation changes, format conversion.
     */
    open var activeFormat: AVCaptureDevice.Format

    
    /**
     @property activeVideoMinFrameDuration
     @abstract
        A property indicating the receiver's current active minimum frame duration (the reciprocal of its max frame rate).
     
     @discussion
        An AVCaptureDevice's activeVideoMinFrameDuration property is the reciprocal of its active maximum frame rate. To limit the max frame rate of the capture device, clients may set this property to a value supported by the receiver's activeFormat (see AVCaptureDeviceFormat's videoSupportedFrameRateRanges property). Clients may set this property's value to kCMTimeInvalid to return activeVideoMinFrameDuration to its default value for the given activeFormat.
     
        -setActiveVideoMinFrameDuration: throws an NSInvalidArgumentException if set to an unsupported value.
     
        -setActiveVideoMinFrameDuration: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:.
     
        Clients can observe automatic changes to the receiver's activeVideoMinFrameDuration by key value observing this property.
     
        On iOS, the receiver's activeVideoMinFrameDuration resets to its default value under the following conditions:
            - The receiver's activeFormat changes
            - The receiver's AVCaptureDeviceInput's session's sessionPreset changes
            - The receiver's AVCaptureDeviceInput is added to a session
     
        When exposureMode is AVCaptureExposureModeCustom, setting the activeVideoMinFrameDuration affects max frame rate, but not exposureDuration. You may use setExposureModeCustomWithDuration:ISO:completionHandler: to set a shorter exposureDuration than your activeVideoMinFrameDuration, if desired.
     */
    open var activeVideoMinFrameDuration: CMTime

    
    /**
     @property activeVideoMaxFrameDuration
     @abstract
        A property indicating the receiver's current active maximum frame duration (the reciprocal of its min frame rate).
     
     @discussion
        An AVCaptureDevice's activeVideoMaxFrameDuration property is the reciprocal of its active minimum frame rate. To limit the min frame rate of the capture device, clients may set this property to a value supported by the receiver's activeFormat (see AVCaptureDeviceFormat's videoSupportedFrameRateRanges property). Clients may set this property's value to kCMTimeInvalid to return activeVideoMaxFrameDuration to its default value for the given activeFormat.
     
        -setActiveVideoMaxFrameDuration: throws an NSInvalidArgumentException if set to an unsupported value.
     
        -setActiveVideoMaxFrameDuration: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:.
     
        Clients can observe automatic changes to the receiver's activeVideoMaxFrameDuration by key value observing this property.
     
        On iOS, the receiver's activeVideoMaxFrameDuration resets to its default value under the following conditions:
            - The receiver's activeFormat changes
            - The receiver's AVCaptureDeviceInput's session's sessionPreset changes
            - The receiver's AVCaptureDeviceInput is added to a session
     
        When exposureMode is AVCaptureExposureModeCustom, frame rate and exposure duration are interrelated. If you call setExposureModeCustomWithDuration:ISO:completionHandler: with an exposureDuration longer than the current activeVideoMaxFrameDuration, the activeVideoMaxFrameDuration will be lengthened to accommodate the longer exposure time. Setting a shorter exposure duration does not automatically change the activeVideoMinFrameDuration or activeVideoMaxFrameDuration. To explicitly increase the frame rate in custom exposure mode, you must set the activeVideoMaxFrameDuration to a shorter value. If your new max frame duration is shorter than the current exposureDuration, the exposureDuration will shorten as well to accommodate the new frame rate.
     */
    @available(macOS 10.9, *)
    open var activeVideoMaxFrameDuration: CMTime

    
    /**
     @property inputSources
     @abstract
        An array of AVCaptureDeviceInputSource objects supported by the receiver.
     
     @discussion
        Some devices can capture data from one of multiple data sources (different input jacks on the same audio device, for example). For devices with multiple possible data sources, inputSources can be used to enumerate the possible choices. Clients can observe automatic changes to the receiver's inputSources by key value observing this property.
     */
    open var inputSources: [AVCaptureDevice.InputSource] { get }

    
    /**
     @property activeInputSource
     @abstract
        The currently active input source of the receiver.
     
     @discussion
        This property can be used to get or set the currently active device input source. -setActiveInputSource: throws an NSInvalidArgumentException if set to a value not present in the inputSources array. -setActiveInputSource: throws an NSGenericException if called without first obtaining exclusive access to the receiver using lockForConfiguration:. Clients can observe automatic changes to the receiver's activeInputSource by key value observing this property.
     */
    open var activeInputSource: AVCaptureDevice.InputSource?
}
extension AVCaptureDevice {

    
    /**
     @enum AVCaptureDevicePosition
     @abstract
        Constants indicating the physical position of an AVCaptureDevice's hardware on the system.
     
     @constant AVCaptureDevicePositionUnspecified
        Indicates that the device's position relative to the system hardware is unspecified.
     @constant AVCaptureDevicePositionBack
        Indicates that the device is physically located on the back of the system hardware.
     @constant AVCaptureDevicePositionFront
        Indicates that the device is physically located on the front of the system hardware.
     */
    @available(macOS 10.7, *)
    public enum Position : Int, @unchecked Sendable {

        
        case unspecified = 0

        case back = 1

        case front = 2
    }

    
    /**
     @group AVCaptureDeviceType string constants
     
     @discussion
        The AVCaptureDeviceType string constants are intended to be used in combination with the AVCaptureDeviceDiscoverySession class to obtain a list of devices matching certain search criteria.
     */
    @available(macOS 10.15, *)
    public struct DeviceType : Hashable, Equatable, RawRepresentable, @unchecked Sendable {

        public init(rawValue: String)
    }

    
    /**
     @enum AVCapturePrimaryConstituentDeviceSwitchingBehavior
     @abstract
        These constants can be used to control when the virtual device is allowed to switch the active primary constituent device.
     
     @constant AVCapturePrimaryConstituentDeviceSwitchingBehaviorUnsupported
        Indicates that the device does not support constituent device switching. This is reported for cameras that do not have more than one constituent device.
     @constant AVCapturePrimaryConstituentDeviceSwitchingBehaviorAuto
        Automatically select the best camera for the current scene. In this mode there are no restrictions on when a camera switch can occur.
     @constant AVCapturePrimaryConstituentDeviceSwitchingBehaviorRestricted
        Restrict fallback camera selection to certain conditions (see AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions). Camera switches necessary to satisfy the requested video zoom factor are still allowed without restriction.
     @constant AVCapturePrimaryConstituentDeviceSwitchingBehaviorLocked
        Lock camera switching to the active primary constituent device. Note that this restricts the minAvailableVideoZoomFactor to the switch-over zoom factor of the activePrimaryConstituentDevice (as reported in AVCaptureDevice.virtualDeviceSwitchOverVideoZoomFactors).
     
     @discussion
        Virtual devices with multiple constituent video devices (such as the Dual Camera, Dual Wide Camera, or Triple Camera), consist of cameras that each have different properties such as focal length, maximum light sensitivity, and minimum focus distance. One of the constituent video devices is selected as the primary constituent device. For an AVCaptureSession, the primary constituent device produces for all outputs. For an AVCaptureMultiCamSession, the primary constituent device produces for all outputs connected to the virtual device's native AVCaptureDeviceInputPort (where its sourceDeviceType is equal to the virtual device's deviceType).
    
        When the requested zoom factor can be achieved by multiple constituent cameras (see -virtualDeviceSwitchOverVideoZoomFactors), the virtual device chooses the best camera for the scene. The primary condition for this is the focal length; the camera with the longest focal length requires the least amount of digital upscaling and therefore normally provides the highest image quality. Secondary conditions are focus and exposure; when the scene requires focus or exposure to go beyond the limits of the active primary constituent device, a camera with a shorter focal length may be able to deliver a better quality image. Such a device is called a fallback primary constituent device. For example, a telephoto camera with a minimum focus distance of 40cm is not able to deliver a sharp image when the subject in the scene is closer than 40cm. For such a scene, the virtual device will switch to the wide-angle camera which typically has a smaller minimum focus distance and is able to achieve accurate focus on the subject. In this case the wide-angle camera is the fallback primary constitute device.
     */
    @available(macOS 12.0, *)
    public enum PrimaryConstituentDeviceSwitchingBehavior : Int, @unchecked Sendable {

        
        case unsupported = 0

        case auto = 1

        case restricted = 2

        case locked = 3
    }

    
    /**
     @enum AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions
     @abstract
        These constants can be used and combined to control the conditions that allow fallback camera selection when the primaryConstituentDeviceSelectionBehavior is set to AVCapturePrimaryConstituentDeviceSwitchingBehaviorRestricted. Note that camera switching necessary to satisfy the requested zoom factor is still allowed.
     
     @constant AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionNone
        Disallow fallback switching.
     @constant AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionVideoZoomChanged
        Restrict fallback camera switching to when the video zoom factor changes, either through AVCaptureDevice.videoZoomFactor or -[AVCaptureDevice rampToVideoZoomFactor:withRate:]. Note that any change in video zoom factor will allow a switch to a fallback camera, not just changes across switch-over zoom factors.
     @constant AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionFocusModeChanged
        Restrict fallback camera switches to when AVCaptureDevice.focusMode is set.
     @constant AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionExposureModeChanged
        Restrict fallback camera switches to when AVCaptureDevice.exposureMode is set.
     
     @discussion
        Whenever triggered by one or more of the enabled conditions, the fallback camera switching waits for exposure and focus to stabilize before deciding which camera to use as the primary constituent device.
     
        Whenever AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionVideoZoomChanged is not included in the restricted switching behavior conditions, AVCapturePrimaryConstituentDeviceSwitchingBehaviorRestricted still allows camera selection when a change in video zoom factor makes a camera eligible or ineligible to be selected as the activePrimaryConstituentDevice. When the video zoom factor decreases to below the switch-over zoom factor of the activePrimaryConstituentDevice, a different camera will be selected to satisfy the requested zoom factor. When the video zoom factor increases and crosses a camera's switch-over zoom factor, this camera becomes eligible to be selected as the activePrimaryConstituentDevice. If exposure and focus allow, this camera then becomes the new activePrimaryConstituentDevice. Similar to the AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditionVideoZoomChanged this also waits for exposure and focus to stabilize. Otherwise the activePrimaryConstituentDevice remains unchanged.
     */
    @available(macOS 12.0, *)
    public struct PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions : OptionSet, @unchecked Sendable {

        public init(rawValue: UInt)

        
        public static var videoZoomChanged: AVCaptureDevice.PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions { get }

        public static var focusModeChanged: AVCaptureDevice.PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions { get }

        public static var exposureModeChanged: AVCaptureDevice.PrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions { get }
    }

    
    /**
     @enum AVCaptureFlashMode
     @abstract
        Constants indicating the mode of the flash on the receiver's device, if it has one.
     
     @constant AVCaptureFlashModeOff
        Indicates that the flash should always be off.
     @constant AVCaptureFlashModeOn
        Indicates that the flash should always be on.
     @constant AVCaptureFlashModeAuto
        Indicates that the flash should be used automatically depending on ambient light conditions.
     */
    @available(macOS 10.7, *)
    public enum FlashMode : Int, @unchecked Sendable {

        
        case off = 0

        case on = 1

        case auto = 2
    }

    
    /**
     @enum AVCaptureTorchMode
     @abstract
        Constants indicating the mode of the torch on the receiver's device, if it has one.
     
     @constant AVCaptureTorchModeOff
        Indicates that the torch should always be off.
     @constant AVCaptureTorchModeOn
        Indicates that the torch should always be on.
     @constant AVCaptureTorchModeAuto
        Indicates that the torch should be used automatically depending on ambient light conditions.
     */
    @available(macOS 10.7, *)
    public enum TorchMode : Int, @unchecked Sendable {

        
        case off = 0

        case on = 1

        case auto = 2
    }

    
    /**
     @constant AVCaptureMaxAvailableTorchLevel
        A special value that may be passed to -setTorchModeWithLevel:error: to set the torch to the maximum level currently available. Under thermal duress, the maximum available torch level may be less than 1.0.
     */
    @available(macOS 10.15, *)
    public class let maxAvailableTorchLevel: Float

    
    /**
     @enum AVCaptureFocusMode
     @abstract
        Constants indicating the mode of the focus on the receiver's device, if it has one.
     
     @constant AVCaptureFocusModeLocked
        Indicates that the focus should be locked at the lens' current position.
     @constant AVCaptureFocusModeAutoFocus
        Indicates that the device should autofocus once and then change the focus mode to AVCaptureFocusModeLocked.
     @constant AVCaptureFocusModeContinuousAutoFocus
        Indicates that the device should automatically focus when needed.
     */
    @available(macOS 10.7, *)
    public enum FocusMode : Int, @unchecked Sendable {

        
        case locked = 0

        case autoFocus = 1

        case continuousAutoFocus = 2
    }

    
    /**
     @enum AVCaptureExposureMode
     @abstract
        Constants indicating the mode of the exposure on the receiver's device, if it has adjustable exposure.
     
     @constant AVCaptureExposureModeLocked
        Indicates that the exposure should be locked at its current value.
     @constant AVCaptureExposureModeAutoExpose
        Indicates that the device should automatically adjust exposure once and then change the exposure mode to AVCaptureExposureModeLocked.
     @constant AVCaptureExposureModeContinuousAutoExposure
        Indicates that the device should automatically adjust exposure when needed.
     @constant AVCaptureExposureModeCustom
        Indicates that the device should only adjust exposure according to user provided ISO, exposureDuration values.
     */
    @available(macOS 10.7, *)
    public enum ExposureMode : Int, @unchecked Sendable {

        
        case locked = 0

        case autoExpose = 1

        case continuousAutoExposure = 2

        @available(macOS 10.15, *)
        case custom = 3
    }

    
    /**
     @enum AVCaptureWhiteBalanceMode
     @abstract
        Constants indicating the mode of the white balance on the receiver's device, if it has adjustable white balance.
     
     @constant AVCaptureWhiteBalanceModeLocked
        Indicates that the white balance should be locked at its current value.
     @constant AVCaptureWhiteBalanceModeAutoWhiteBalance
        Indicates that the device should automatically adjust white balance once and then change the white balance mode to AVCaptureWhiteBalanceModeLocked.
     @constant AVCaptureWhiteBalanceModeContinuousAutoWhiteBalance
        Indicates that the device should automatically adjust white balance when needed.
     */
    @available(macOS 10.7, *)
    public enum WhiteBalanceMode : Int, @unchecked Sendable {

        
        case locked = 0

        case autoWhiteBalance = 1

        case continuousAutoWhiteBalance = 2
    }

    
    /**
     @typedef
     @abstract
        A constant that is used to specify the transport controls' speed.
     */
    @available(macOS 10.7, *)
    public typealias TransportControlsSpeed = Float

    
    /**
     @enum AVCaptureDeviceTransportControlsPlaybackMode
     @abstract
        Constants indicating the transport controls' current mode of play back, if it has one.
     
     @constant AVCaptureDeviceTransportControlsNotPlayingMode
        Indicates that the tape transport is not threaded through the play head.
     @constant AVCaptureDeviceTransportControlsPlayingMode
        Indicates that the tape transport is threaded through the play head.
     */
    @available(macOS 10.7, *)
    public enum TransportControlsPlaybackMode : Int, @unchecked Sendable {

        
        case notPlaying = 0

        case playing = 1
    }

    
    /**
     @enum AVCaptureCenterStageControlMode
     @abstract
        Constants indicating the current Center Stage control mode.
     
     @constant AVCaptureCenterStageControlModeUser
        Indicates that the application is unaware of the Center Stage feature. Its enablement is entirely under user control in Control Center.
     @constant AVCaptureCenterStageControlModeApp
        Indicates that the application controls the Center Stage feature, disallowing input from the user in Control Center.
     @constant AVCaptureCenterStageControlModeCooperative
        Indicates that both the user and application cooperatively share control of the Center Stage feature.
     */
    @available(macOS 12.3, *)
    public enum CenterStageControlMode : Int, @unchecked Sendable {

        
        case user = 0

        case app = 1

        case cooperative = 2
    }

    
    /*!
     @property centerStageControlMode
     @abstract
        A class property indicating the current mode of Center Stage control (user, app, or cooperative).
     
     @discussion
        This class property determines how the Center Stage feature is controlled. When set to the default value of AVCaptureCenterStageControlModeUser, centerStageEnabled may not be set programmatically and throws an NSInvalidArgumentException. In User mode, the feature may only be set by the user in Control Center. If you wish to take Center Stage control away from the user and exclusively enable / disable it programmatically, set this property to AVCaptureCenterStageControlModeApp. When under exclusive app control, Center Stage user control is disallowed (for instance, the toggle is grayed out in Control Center). If you wish to take control of Center Stage, but also cooperate with the user by listening for and appropriately reacting to their changes to the centerStageEnabled property, set this property to AVCaptureCenterStageControlModeCooperative. Note that in this mode, the onus is on you, the app developer, to honor user intent and conform your AVCaptureSession configuration to make Center Stage active (see the AVCaptureDevice instance property centerStageActive). In cooperative mode, the centerStageEnabled property may change at any time (such as when the user enables / disables the feature in Control Center).
     */
    
    /*!
     @property centerStageEnabled
     @abstract
        A class property indicating whether the Center Stage feature is currently enabled or disabled (such as in Control Center or programmatically via your app).
     
     @discussion
        This property may only be set if centerStageControlMode is AVCaptureCenterStageControlModeApp or AVCaptureCenterStageControlModeCooperative, and otherwise throws an NSInvalidArgumentException. When centerStageControlMode is AVCaptureCenterStageControlModeUser or AVCaptureCenterStageControlModeCooperative, this property may change according to user desire (such as enabling / disabling the feature in Control Center), so you should key-value observe it.
     */
    
    /*!
     @property centerStageActive
     @abstract
        Indicates whether Center Stage is currently active on a particular AVCaptureDevice.
     
     @discussion
        This readonly property returns YES when Center Stage is currently active on the receiver. When active, the camera automatically adjusts to keep people optimally framed within the field of view. The field of view may pan, tighten or widen as needed. Certain restrictions come into play when Center Stage is active:
            - The device's minAvailableVideoZoomFactor and maxAvailableVideoZoomFactor become restricted (see AVCaptureDeviceFormat's videoMinZoomFactorForCenterStage and videoMaxZoomFactorForCenterStage).
            - The device's activeVideoMinFrameDuration and activeVideoMaxFrameDuration are limited (see AVCaptureDeviceFormat's videoFrameRateRangeForCenterStage).
        Center Stage may be enabled via user control or application control, depending on the current +AVCaptureDevice.centerStageControlMode. When +AVCaptureDevice.centerStageEnabled is YES, a particular AVCaptureDevice instance may return YES for this property, depending whether it supports the feature in its current configuration. Some device features are mutually exclusive to Center Stage:
            - If depth data delivery is enabled on any output, such as AVCaptureDepthDataOutput, or -AVCapturePhotoOutput.depthDataDeliveryEnabled, Center Stage is deactivated.
            - If geometricDistortionCorrectionSupported is YES, geometricDistortionCorrectionEnabled must also be YES, or Center Stage is deactivated.
        This property is key-value observable.
     */
    
    /*!
     @property centerStageRectOfInterestSupported
     @abstract
        Indicates whether the device supports the Center Stage Rect of Interest feature.
     
     @discussion
        This property returns YES if the device supports Center Stage Rect of Interest.
     */
    
    /*!
     @property centerStageRectOfInterest
     @abstract
        Specifies the effective region within the output pixel buffer that will be used to perform Center Stage framing.
     
     @discussion
        Applications that wish to apply additional processing (such as cropping) on top of Center Stage's output can use this property to guide Center Stage's framing.
     
        The rectangle's origin is top left and is relative to the coordinate space of the output pixel buffer. The default value of this property is the value CGRectMake(0, 0, 1, 1), where {0,0} represents the top left of the picture area, and {1,1} represents the bottom right on an unrotated picture. This rectangle of interest is applied prior to rotation, mirroring or scaling.
     
        Pixels outside of this rectangle of interest will be blackened out.
     
        Setting this property has no impact on objects specified in the metadata output.
     
        -setCenterStageRectOfInterest: throws an NSGenericException if called without first obtaining exclusive access to the receiver using -lockForConfiguration:. -setCenterStageRectOfInterest: throws an NSInvalidArgumentException if none of the AVCaptureDeviceFormats supported by the receiver support CenterStage. -setCenterStageRectOfInterest: throws an NSInvalidArgumentException if +centerStageEnabled is NO on the AVCaptureDevice class. -setCenterStageRectOfInterest: throws an NSInvalidArgumentException if the provided rectOfInterest goes outside the normalized (0-1) coordinate space.
     */
    
    /*!
     @property portraitEffectEnabled
     @abstract
        A class property indicating whether the Portrait Effect feature is currently enabled in Control Center.
     
     @discussion
        This property changes to reflect the Portrait Effect state in Control Center. It is key-value observable. On iOS, Portrait Effect only applies to video conferencing apps by default (apps that use "voip" as one of their UIBackgroundModes). Non video conferencing apps may opt in for the Portrait Effect by adding the following key to their Info.plist:
            <key>NSCameraPortraitEffectEnabled</key>
            <true/>
     */
    
    /*!
     @property portraitEffectActive
     @abstract
        Indicates whether Portrait Effect is currently active for a particular AVCaptureDevice.
     
     @discussion
        This readonly property returns YES when Portrait Effect is currently active on the receiver. When active, the device blurs the background, simulating a shallow depth of field effect. Certain restrictions come into play when Portrait Effect is active:
            - The device's activeVideoMinFrameDuration and activeVideoMaxFrameDuration are limited (see AVCaptureDeviceFormat's videoFrameRateRangeForPortraitEffect).
        Note that when +AVCaptureDevice.portraitEffectEnabled is YES, a particular AVCaptureDevice instance may return YES for this property, depending whether it supports the feature in its current configuration.
        This property is key-value observable.
     */
    
    /*!
     @property reactionEffectsEnabled
     @abstract
        A class property indicating whether the application is suitable for reaction effects, either by automatic gesture detection, or by calls to -[AVCaptureDevice performEffectForReaction:]. Reactions are only rendered when the device's activeFormat.reactionEffectsSupported is also YES, which will be reflected by canPerformReactionEffects when the feature is both enabled and supported.
     
     @discussion
        On macOS, Reaction Effects are enabled by default for all applications. On iOS, Reaction Effects are enabled by default for video conferencing applications (apps that use "voip" as one of their UIBackgroundModes). Non video conferencing applications may opt in for Reaction Effects by adding the following key to their Info.plist:
            <key>NSCameraReactionEffectsEnabled</key>
            <true/>
     */
    
    /*!
     @property reactionEffectGesturesEnabled
     @abstract
        A class property indicating whether gesture detection will trigger reaction effects on the video stream. Gesture detection will only run when the device's activeFormat.reactionEffectsSupported is also YES, which will be reflected by canPerformReactionEffects.
     
     @discussion
        This property changes to reflect the Gestures state in Control Center. It is key-value observable. Clients can call performEffectForReaction: independently of whether gesture detection is enabled, reaction effects from either source will be intermixed.
     */
    
    /*!
     @property canPerformReactionEffects
     @abstract
        Indicates whether reactions can be performed on a particular AVCaptureDevice. This requires reactionEffectsEnabled to be YES, as well as using a AVCaptureDeviceFormat with reactionEffectsSupported.
     
     @discussion
        This readonly property returns YES when resources for reactions are available on the device instance. When YES, calls to performEffectForReaction: will render on the video feed, otherwise those calls are ignored. It is key-value observable.
     */
    
    /*!
     @property availableReactionTypes
     @abstract
        Returns a list of reaction types which can be passed to performEffectForReaction.
     
     @discussion
        The list may differ between devices, or be affected by changes to active format, and can be key-value observed.
     */
    
    /*!
     @method performEffectForReaction:
     @abstract
        Triggers a specified reaction on the video stream.
     
     @param reactionType
        Indicates which reaction to perform.
     
     @discussion
        The entries in reactionEffectsInProgress may not reflect one-to-one against calls to this method. Depending on reaction style or resource limits, triggering multiple overlapping reactions of the same type may be coalesced into extending an existing reaction rather than overlaying a new one.
        
        The reactionType requested must be one of those listed in availableReactionTypes or an exception will be thrown. Performing a reaction when canPerformReactionEffects is NO is ignored, and VoIP applications are encouraged to transmit and display such reactions outside of the video feed.
     */
    
    /*!
     @property reactionEffectsInProgress
     @abstract
        Contains an array of reaction effects that are currently being performed by the device, sorted by timestamp. If observing old and new values in the KVO callback, the reaction effects which are still running in the new array will have kCMTimeInvalid as their endTime property. Reaction effects which have ended will only be in the old array, and will have their endTime property set to the presentation time of the first frame where the reaction effect was no longer present.
     
     @discussion
        Reaction effects which are triggered by either a call to performEffectForReaction: or by the automatic gesture detection will be reflected in this array. It is key-value observable to be notified when reaction effects begin or end.
     */
    
    /*!
     @property continuityCamera
     @abstract
        A property that reports YES if the receiver is a Continuity Camera.
     
     @discussion
        Access this property to discover if the receiver is a Continuity Camera (external iPhone webcam).
    */
    
    /*!
     @property companionDeskViewCamera
     @abstract
        A reference to the Desk View Camera that is associated with and derived from this camera.
     
     @discussion
        The companionDeskViewCamera property allows you to discover if the receiver has a paired Desk View Camera which derives its desk framing from the receiver's ultra wide frame. In the presence of multiple Continuity Cameras, this property allows you to pair a particular Continuity Camera with its associated Desk View Camera.
    */
    
    /**
     @enum AVCaptureMicrophoneMode
     @abstract
        Constants describing microphone filtering modes.
    
     @constant AVCaptureMicrophoneModeStandard
        Indicates that microphone audio is being processed with standard voice DSP.
     @constant AVCaptureMicrophoneModeWideSpectrum
        Indicates that microphone audio processing is minimized to capture all sounds in the room.
     @constant AVCaptureMicrophoneModeVoiceIsolation
        Indicates that microphone audio is being processed to isolate the voice and attenuate other signals.
     */
    @available(macOS 12.0, *)
    public enum MicrophoneMode : Int, @unchecked Sendable {

        
        case standard = 0

        case wideSpectrum = 1

        case voiceIsolation = 2
    }

    
    /*!
     @property preferredMicrophoneMode
     @abstract
        Indicates the microphone mode that has been selected by the user in Control Center.
    
     @discussion
        This readonly property returns the microphone mode selected by the user in Control Center. It is key-value observable.
     */
    
    /*!
     @property activeMicrophoneMode
     @abstract
        Indicates the currently active microphone mode.
    
     @discussion
        This readonly property returns the currently active microphone mode, which may differ from the preferredMicrophoneMode if the application's active audio route does not support the preferred microphone mode. This property is key-value observable.
     */
    
    /**
     @enum AVCaptureSystemUserInterface
     @abstract
        Constants describing the system user interfaces available to +showSystemUserInterface:.
     
     @constant AVCaptureSystemUserInterfaceVideoEffects
        Indicates the system UI for enabling / disabling video effects.
     @constant AVCaptureSystemUserInterfaceMicrophoneModes
        Indicates the system UI for selecting microphone modes.
     */
    @available(macOS 12.0, *)
    public enum SystemUserInterface : Int, @unchecked Sendable {

        
        case videoEffects = 1

        case microphoneModes = 2
    }

    
    /*!
     @method showSystemUserInterface:
     @abstract
        Displays the system's user interface for video effects or microphone modes.
     
     @param systemUserInterface
        The system UI to show.
     
     @discussion
        This method allows the calling application to prompt the user to make changes to Video Effects (such as Center Stage or the Portrait Effect) or Microphone Modes. It brings up the system user interface and deep links to the appropriate module. This method is non-blocking. After presenting the desired system user interface, control returns immediately to the application.
     */
    
    
    /**
     @class AVCaptureDeviceDiscoverySession
     @abstract
        The AVCaptureDeviceDiscoverySession allows clients to search for devices by certain criteria.
     
     @discussion
        This class allows clients to discover devices by providing certain search criteria. The objective of this class is to help find devices by device type and optionally by media type or position and allow you to key-value observe changes to the returned devices list.
     */
    @available(macOS 10.15, *)
    open class DiscoverySession : NSObject {

        
        /**
         @method discoverySessionWithDeviceTypes:
         @abstract
            Returns an AVCaptureDeviceDiscoverySession instance for the given device types, media type, and position.
         
         @param deviceTypes
            An array specifying the device types to include in the list of discovered devices.
         @param mediaType
            The media type, such as AVMediaTypeVideo, AVMediaTypeAudio, or AVMediaTypeMuxed, to include in the list of discovered devices. Pass nil to search for devices with any media type.
         @param position
            The position to include in the list of discovered devices. Pass AVCaptureDevicePositionUnspecified to search for devices with any position.
         @result
            The AVCaptureDeviceDiscoverySession from which the list of devices can be obtained.
         
         @discussion
            The list of device types is mandatory. This is used to make sure that clients only get access to devices of types they expect. This prevents new device types from automatically being included in the list of devices.
         */
        public convenience init(deviceTypes: [AVCaptureDevice.DeviceType], mediaType: AVMediaType?, position: AVCaptureDevice.Position)

        
        /**
         @property devices
         @abstract
            The list of devices that comply to the search criteria specified on the discovery session.
         
         @discussion
            The returned array contains only devices that are available at the time the method is called. Applications can key-value observe this property to be notified when the list of available devices has changed. For apps linked against iOS 10, the devices returned are unsorted. For apps linked against iOS 11 or later, the devices are sorted by AVCaptureDeviceType, matching the order specified in the deviceTypes parameter of +[AVCaptureDeviceDiscoverySession discoverySessionWithDeviceTypes:mediaType:position:]. If a position of AVCaptureDevicePositionUnspecified is specified, the results are further ordered by position in the AVCaptureDevicePosition enum. Starting in Mac Catalyst 14.0, clients can key value observe the value of this property to be notified when the devices change.
         */
        open var devices: [AVCaptureDevice] { get }
    }

    
    
    /**
     @class AVCaptureDeviceRotationCoordinator
     @abstract
        The AVCaptureDeviceRotationCoordinator allows clients to monitor rotations of a given AVCaptureDevice instance and be provided the video rotation angle that should be applied for horizon-level preview and capture relative to gravity.
     
     @discussion
        Each instance of AVCaptureDeviceRotationCoordinator allows a client to coordinate with changes to the rotation of an AVCaptureDevice to ensure the camera's video preview and captured output are horizon-level. The coordinator delivers key-value updates on the main queue.
     */
    @available(macOS 14.0, *)
    open class RotationCoordinator : NSObject {

        
        /**
         @method initWithDevice:previewLayer:
         @abstract
            Returns an AVCaptureDeviceRotationCoordinator instance that provides updates to the amount of rotation that should be applied for horizon-level preview and capture relative to gravity.
         
         @param device
            The device for which to monitor rotation.
         @param previewLayer
            A layer displaying the camera's video preview. If nil, the coordinator will return 0 degrees of rotation for horizon-level preview.
         @result
            An AVCaptureDeviceRotationCoordinator from which rotation angles for preview and capture can be obtained.
         
         @discussion
            An AVCaptureDeviceRotationCoordinator is only applicable to video devices. The given device and layer determine the amount of rotation that should be applied for horizon-level preview and capture.
         */
        public init(device: AVCaptureDevice, previewLayer: CALayer?)

        
        /**
         @property device
         @abstract
            The the device for which the coordinator provides video rotation angles.
         
         @discussion
            The value of this property is the AVCaptureDevice instance that was used to create the coordinator. The coordinator holds a weak reference to the device.
         */
        weak open var device: AVCaptureDevice? { get }

        
        /**
         @property previewLayer
         @abstract
            The CALayer for which the coordinator calculates video rotation angles for horizon-level preview.
         
         @discussion
            The value of this property is the CALayer instance that was used to create the coordinator. Clients may specify an AVCaptureVideoPreviewLayer or other CALayer instance that displays a camera's video preview. The coordinator holds a weak reference to the layer. The coordinator will return 0 degrees of rotation from -videoRotationAngleForHorizonLevelPreview if a layer was not specified at initialization, the layer is not in a view hierarchy, or the layer has been deallocated.
         */
        weak open var previewLayer: CALayer? { get }

        
        /**
         @property videoRotationAngleForHorizonLevelPreview
         @abstract
            Returns a video rotation angle in degrees for displaying the camera's video preview in the given CALayer.
         
         @discussion
            The video rotation angle represents by how much the camera's video preview should be rotated for display in the CALayer to be horizon-level relative to gravity. An angle of 0 degrees means that video will be output in the camera's unrotated, native sensor orientation. The video rotation angle for preview may differ between cameras at different positions. For example when an iOS device is held in portrait orientation, the video preview for built-in cameras may need to be rotated by 90 degrees while the video preview for an external camera should not be rotated. External cameras return 0 degrees of rotation even if they physically rotate when their position in physical space is unknown. This property is key-value observable and delivers updates on the main queue.
         */
        open var videoRotationAngleForHorizonLevelPreview: CGFloat { get }

        
        /**
         @property videoRotationAngleForHorizonLevelCapture
         @abstract
            Returns a video rotation angle in degrees for horizon-level capture from this camera.
         
         @discussion
            The video rotation angle represents by how much the photos or movies captured from the camera should be rotated to be horizon-level relative to gravity. A video rotation angle of 0 degrees means that the output will be in the camera's unrotated, native sensor orientation. The video rotation angle for capture may differ between cameras. For example when an iOS device is held in portrait orientation, photos and movies captured from built-in cameras may need to be rotated by 90 degrees while the photos and movies from an external camera should not be rotated. External cameras return 0 degrees of rotation even if they physically rotate when their position in physical space is unknown. The video rotation angle returned from this property is distinct from the angle returned by -videoRotationAngleForHorizonLevelPreview because in certain combinations of device and interface orientations, the video rotation angle needed for horizon-level preview may not match the amount of rotation needed for horizon-level capture. This property is key-value observable and delivers updates on the main queue.
         */
        open var videoRotationAngleForHorizonLevelCapture: CGFloat { get }
    }

    
    /*!
     @class AVFrameRateRange
     @abstract
        An AVFrameRateRange expresses a range of valid frame rates as min and max rate and min and max duration.
     
     @discussion
        An AVCaptureDevice exposes an array of formats, and its current activeFormat may be queried. The payload for the formats property is an array of AVCaptureDeviceFormat objects and the activeFormat property payload is an AVCaptureDeviceFormat. AVCaptureDeviceFormat wraps a CMFormatDescription and expresses a range of valid video frame rates as an NSArray of AVFrameRateRange objects. AVFrameRateRange expresses min and max frame rate as a rate in frames per second and duration (CMTime). An AVFrameRateRange object is immutable. Its values do not change for the life of the object.
     */
    
    /*!
     @property minFrameRate
     @abstract
        A Float64 indicating the minimum frame rate supported by this range.
     
     @discussion
        This read-only property indicates the minimum frame rate supported by this range in frames per second.
     */
    
    /*!
     @property maxFrameRate
     @abstract
        A Float64 indicating the maximum frame rate supported by this range.
     
     @discussion
        This read-only property indicates the maximum frame rate supported by this range in frames per second.
     */
    
    /*!
     @property maxFrameDuration
     @abstract
        A CMTime indicating the maximum frame duration supported by this range.
     
     @discussion
        This read-only property indicates the maximum frame duration supported by this range. It is the reciprocal of minFrameRate, and expresses minFrameRate as a duration.
     */
    
    /*!
     @property minFrameDuration
     @abstract
        A CMTime indicating the minimum frame duration supported by this range.
     
     @discussion
        This read-only property indicates the minimum frame duration supported by this range. It is the reciprocal of maxFrameRate, and expresses maxFrameRate as a duration.
     */
    
    /*!
     @class AVZoomRange
     @abstract
        An AVZoomRange expresses an inclusive range of supported zoom factors.
     
     @discussion
        This is used by features that have requirements on zoom factors falling within certain ranges.
     */
    
    /*!
    @property minZoomFactor
    @abstract
        A CGFloat indicating the minimum zoom factor supported by this range.
    */
    
    /*!
    @property maxZoomFactor
    @abstract
        A CGFloat indicating the maximum zoom factor supported by this range.
     */
    
    /*!
    @method containsZoomFactor:
    @abstract
        Tests if a given zoom factor is within the zoom range.
     
    @param zoomFactor
        The zoom factor to test.
    @result
        Returns YES if the given zoom factor is within the zoom range, NO otherwise.
     
    @discussion
         Note that the zoom ranges are inclusive.
     */
    
    /*!
     @enum AVCaptureVideoStabilizationMode
     @abstract
        Constants indicating the modes of video stabilization supported by the device's format.
     
     @constant AVCaptureVideoStabilizationModeOff
        Indicates that video should not be stabilized.
     @constant AVCaptureVideoStabilizationModeStandard
        Indicates that video should be stabilized using the standard video stabilization algorithm introduced with iOS 5.0. Standard video stabilization has a reduced field of view. Enabling video stabilization may introduce additional latency into the video capture pipeline.
     @constant AVCaptureVideoStabilizationModeCinematic
        Indicates that video should be stabilized using the cinematic stabilization algorithm for more dramatic results. Cinematic video stabilization has a reduced field of view compared to standard video stabilization. Enabling cinematic video stabilization introduces much more latency into the video capture pipeline than standard video stabilization and consumes significantly more system memory. Use narrow or identical min and max frame durations in conjunction with this mode.
     @constant AVCaptureVideoStabilizationModeCinematicExtended
        Indicates that the video should be stabilized using the extended cinematic stabilization algorithm. Enabling extended cinematic stabilization introduces longer latency into the video capture pipeline compared to the AVCaptureVideoStabilizationModeCinematic and consumes more memory, but yields improved stability. It is recommended to use identical or similar min and max frame durations in conjunction with this mode.
     @constant AVCaptureVideoStabilizationModePreviewOptimized
        Indicates that video should be stabilized using the preview optimized stabilization algorithm. Preview stabilization is a low latency and low power algorithm which is supported only on connections which either have an associated preview layer or have a preview-sized VideoDataOutput.
     @constant AVCaptureVideoStabilizationModeAuto
        Indicates that the most appropriate video stabilization mode for the device and format should be chosen.
     */
    
    /*!
     @enum AVCaptureAutoFocusSystem
     @abstract
        Constants indicating the autofocus system.
     
     @constant AVCaptureAutoFocusSystemNone
        Indicates that autofocus is not available.
     @constant AVCaptureAutoFocusSystemContrastDetection
        Indicates that autofocus is achieved by contrast detection. Contrast detection performs a focus scan to find the optimal position.
     @constant AVCaptureAutoFocusSystemPhaseDetection
        Indicates that autofocus is achieved by phase detection. Phase detection has the ability to achieve focus in many cases without a focus scan. Phase detection autofocus is typically less visually intrusive than contrast detection autofocus.
     */
    
    
    /**
     @class AVCaptureDeviceFormat
     @abstract
        An AVCaptureDeviceFormat wraps a CMFormatDescription and other format-related information, such as min and max framerate.
     
     @discussion
        An AVCaptureDevice exposes an array of formats, and its current activeFormat may be queried. The payload for the formats property is an array of AVCaptureDeviceFormat objects and the activeFormat property payload is an AVCaptureDeviceFormat. AVCaptureDeviceFormat is a thin wrapper around a CMFormatDescription, and can carry associated device format information that doesn't go in a CMFormatDescription, such as min and max frame rate. An AVCaptureDeviceFormat object is immutable. Its values do not change for the life of the object.
     */
    @available(macOS 10.7, *)
    open class Format : NSObject {

        
        /**
         @property mediaType
         @abstract
            An NSString describing the media type of an AVCaptureDevice active or supported format.
         
         @discussion
            Supported mediaTypes are listed in AVMediaFormat.h. This is a read-only property. The caller assumes no ownership of the returned value and should not CFRelease it.
         */
        open var mediaType: AVMediaType { get }

        
        /**
         @property formatDescription
         @abstract
            A CMFormatDescription describing an AVCaptureDevice active or supported format.
         
         @discussion
            A CMFormatDescription describing an AVCaptureDevice active or supported format. This is a read-only property. The caller assumes no ownership of the returned value and should not CFRelease it.
         */
        open var formatDescription: CMFormatDescription { get }

        
        /**
         @property videoSupportedFrameRateRanges
         @abstract
            A property indicating the format's supported frame rate ranges.
         
         @discussion
            videoSupportedFrameRateRanges is an array of AVFrameRateRange objects, one for each of the format's supported video frame rate ranges.
         */
        open var videoSupportedFrameRateRanges: [AVFrameRateRange] { get }

        
        /**
         @property highPhotoQualitySupported
         @abstract
            A boolean value specifying whether this format supports high photo quality when selecting an AVCapturePhotoQualityPrioritization of .balanced or .quality.
         
         @discussion
            If an AVCaptureDeviceFormat's highPhotoQualitySupported property is YES, the format produces higher image quality when selecting .balanced or .quality AVCapturePhotoQualityPrioritization compared to .speed. Such formats adhere to the following rules:
                - Photo requests with a prioritization of .speed produce the fastest image result (suitable for burst captures).
                - Photo requests with a prioritization of .balanced produce higher image quality without dropping frames if a video recording is underway.
                - Photo requests with a prioritization of .quality produce high image quality and may cause frame drops if a video recording is underway. For maximum backward compatibility, photo requests on high photo quality formats set to .quality only cause video frame drops if your app is linked on or after iOS 15.
            Formats that don't support high photo quality produce the same image quality whether you select .speed, .balanced, or .quality. Note that high photo quality is only attainable when using the AVCapturePhotoOutput with these supported formats.
         */
        @available(macOS 12.0, *)
        open var isHighPhotoQualitySupported: Bool { get }

        
        /**
         @property autoFocusSystem
         @abstract
            A property indicating the autofocus system.
         
         @discussion
            This read-only property indicates the autofocus system.
         */
        @available(macOS 10.15, *)
        open var autoFocusSystem: AVCaptureDevice.Format.AutoFocusSystem { get }

        
        /**
        @property zoomFactorsOutsideOfVideoZoomRangesForDepthDeliverySupported
        @abstract
            This property returns whether the format supports zoom factors outside of the supportedVideoZoomFactorRangesForDepthDataDelivery.
        
        @discussion
            When a zoom factor outside of the supportedVideoZoomFactorRangesForDepthDataDelivery is set, depth data delivery will be suspended until a zoom factor within the supportedVideoZoomFactorRangesForDepthDataDelivery is set.
         */
        @available(macOS 14.2, *)
        open var zoomFactorsOutsideOfVideoZoomRangesForDepthDeliverySupported: Bool { get }
    }

    
    /*
     @property portraitEffectsMatteStillImageDeliverySupported
     @abstract
        Indicates whether this depth format supports the delivery of a portrait effects matte.
     
     @discussion
        Some depth formats are capable of producing an auxiliary matting image (similar to an auxiliary depth image) tuned for high quality portrait effects rendering (see AVPortraitEffectsMatte.h). If this property's value is YES, you may request portrait effects matte delivery in your photos using the AVCapturePhotoOutput, provided this format is selected as the activeDepthDataFormat.
     */
    
    /*!
     @property multiCamSupported
     @abstract
        A property indicating whether this format is supported in an AVCaptureMultiCamSession.
     
     @discussion
       When using an AVCaptureSession (single camera capture), any of the formats in the device's -formats array may be set as the -activeFormat. However, when used with an AVCaptureMultiCamSession, the device's -activeFormat may only be set to one of the formats for which multiCamSupported answers YES. This limited subset of capture formats are known to run sustainably in a multi camera capture scenario.
     */
    
    /*!
     @property geometricDistortionCorrectedVideoFieldOfView
     @abstract
        A property indicating the format's horizontal field of view post geometric distortion correction.
     
     @discussion
        If the receiver's AVCaptureDevice does not support GDC, geometricDistortionCorrectedVideoFieldOfView matches the videoFieldOfView property.
     */
    
    /*!
     @property centerStageSupported
     @abstract
        Indicates whether the format supports the Center Stage feature.
     
     @discussion
        This property returns YES if the format supports "Center Stage", which automatically adjusts the camera to keep people optimally framed within the field of view. See +AVCaptureDevice.centerStageEnabled for a detailed discussion.
     */
    
    /*
     @property videoMinZoomFactorForCenterStage
     @abstract
        Indicates the minimum zoom factor available for the AVCaptureDevice's videoZoomFactor property when centerStageActive is YES.
     
     @discussion
        Devices support a limited zoom range when Center Stage is active. If this device format does not support Center Stage, this property returns 1.0.
     */
    
    /*!
     @property videoMaxZoomFactorForCenterStage
     @abstract
        Indicates the maximum zoom factor available for the AVCaptureDevice's videoZoomFactor property when centerStageActive is YES.
     
     @discussion
        Devices support a limited zoom range when Center Stage is active. If this device format does not support Center Stage, this property returns videoMaxZoomFactor.
     */
    
    /*!
     @property videoFrameRateRangeForCenterStage
     @abstract
        Indicates the minimum / maximum frame rates available when centerStageActive is YES.
     
     @discussion
        Devices may support a limited frame rate range when Center Stage is active. If this device format does not support Center Stage, this property returns nil.
     */
    
    /*!
     @property portraitEffectSupported
     @abstract
        Indicates whether the format supports the Portrait Effect feature.
     
     @discussion
        This property returns YES if the format supports Portrait Effect, the application of a shallow depth of field effect to objects in the background. See +AVCaptureDevice.portraitEffectEnabled for a detailed discussion.
     */
    
    /*!
     @property videoFrameRateRangeForPortraitEffect
     @abstract
        Indicates the minimum / maximum frame rates available when portraitEffectActive is YES.
     
     @discussion
        Devices may support a limited frame rate range when Portrait Effect is active. If this device format does not support Portrait Effect, this property returns nil.
     */
    
    /*!
     @property studioLightEnabled
     @abstract
        A class property indicating whether the Studio Light feature is currently enabled in Control Center.
     
     @discussion
        This property changes to reflect the Studio Light state in Control Center. It is key-value observable.  On iOS, Studio Light only applies to video conferencing apps by default (apps that use "voip" as one of their UIBackgroundModes). Non video conferencing apps may opt in for Studio Light by adding the following key to their Info.plist:
            <key>NSCameraStudioLightEnabled</key>
            <true/>
     */
    
    /*!
     @property studioLightActive
     @abstract
        Indicates whether Studio Light is currently active on a particular AVCaptureDevice.
     
     @discussion
        This readonly property returns YES when Studio Light is currently active on the receiver. When active, the subject's face is artificially lit to simulate the presence of a studio light near the camera.
     */
    
    /*!
     @property studioLightSupported
     @abstract
        Indicates whether the format supports the Studio Light feature.
     
     @discussion
        This property returns YES if the format supports Studio Light (artificial re-lighting of the subject's face). See +AVCaptureDevice.studioLightEnabled.
     */
    
    /*!
     @property videoFrameRateRangeForStudioLight
     @abstract
        Indicates the minimum / maximum frame rates available when studioLight is YES.
     
     @discussion
        Devices may support a limited frame rate range when Studio Light is active. If this device format does not support Studio Light, this property returns nil.
     */
    
    /*!
     @property reactionEffectsSupported
     @abstract
        Indicates whether the format supports the Reaction Effects feature.
     
     @discussion
        This property returns YES if the format supports Reaction Effects. See +AVCaptureDevice.reactionEffectsEnabled.
     */
    
    /*!
     @property videoFrameRateRangeForReactionEffectsInProgress
     @abstract
        Indicates the minimum / maximum frame rates available when a reaction effect is running.
     
     @discussion
        Unlike the other video effects, enabling reaction effects does not limit the stream's frame rate because most of the time no rendering is being performed. The frame rate will only ramp down when a reaction is actually being rendered on the stream (see AVCaptureDevice.reactionEffectsInProgress)
     */
    
    
    /**
     @class AVCaptureDeviceInputSource
     @abstract
        An AVCaptureDeviceInputSource represents a distinct input source on an AVCaptureDevice object.
     
     @discussion
        An AVCaptureDevice may optionally present an array of inputSources, representing distinct mutually exclusive inputs to the device, for example, an audio AVCaptureDevice might have ADAT optical and analog input sources. A video AVCaptureDevice might have an HDMI input source, or a component input source.
     */
    @available(macOS 10.7, *)
    open class InputSource : NSObject {

        
        /**
         @property inputSourceID
         @abstract
            An ID unique among the inputSources exposed by a given AVCaptureDevice.
         
         @discussion
            An AVCaptureDevice's inputSources array must contain AVCaptureInputSource objects with unique inputSourceIDs.
         */
        open var inputSourceID: String { get }

        
        /**
         @property localizedName
         @abstract
            A localized human-readable name for the receiver.
         
         @discussion
            This property can be used for displaying the name of the capture device input source in a user interface.
         */
        open var localizedName: String { get }
    }
}
@available(macOS 10.7, *)
extension AVCaptureDevice {

    /**
     @property position
     @abstract
        Indicates the physical position of an AVCaptureDevice's hardware on the system.
     
     @discussion
        The value of this property is an AVCaptureDevicePosition indicating where the receiver's device is physically located on the system hardware.
     */
    open var position: AVCaptureDevice.Position { get }
}
extension AVCaptureDevice.DeviceType {

    /**
     @constant AVCaptureDeviceTypeExternal
        An external device type. On iPad, external devices are those that conform to the UVC (USB Video Class) specification.
     
     @discussion
        Starting in Mac Catalyst 17.0, apps may opt in for using AVCaptureDeviceTypeExternal by adding the following key to their Info.plist:
            <key>NSCameraUseExternalDeviceType</key>
            <true/>
     
        Otherwise, external cameras on Mac Catalyst report that their device type is AVCaptureDeviceTypeBuiltInWideAngleCamera.
     */
    @available(macOS 14.0, *)
    public static let external: AVCaptureDevice.DeviceType

    /**
     @constant AVCaptureDeviceTypeMicrophone
        A microphone. On iOS and tvOS, only one AVCaptureDevice of type AVCaptureDeviceTypeMicrophone is exposed to the system. The audio routing subsystem decides which physical microphone to use, be it a built in microphone, a wired headset, an external microphone, etc. The microphone device's `localizedName` will change as the audio subsystem switches to a different physical device.
     */
    @available(macOS 14.0, *)
    public static let microphone: AVCaptureDevice.DeviceType

    /**
     @constant AVCaptureDeviceTypeBuiltInWideAngleCamera
        A built-in wide angle camera device. These devices are suitable for general purpose use.
     */
    @available(macOS 10.15, *)
    public static let builtInWideAngleCamera: AVCaptureDevice.DeviceType

    /**
     @constant AVCaptureDeviceTypeContinuityCamera

